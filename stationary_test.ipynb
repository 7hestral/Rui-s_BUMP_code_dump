{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import io\n",
    "from io import StringIO, BytesIO, TextIOWrapper\n",
    "import gzip\n",
    "from datetime import datetime, date\n",
    "from s3_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import ast\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from statsmodels.tsa.stattools import adfuller, acf\n",
    "from utils import *\n",
    "from src.stationary_test_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kalman_df = pd.read_csv('./imputed_df_sleep_fatigue/kalman_impute_df_userid_1032.csv')\n",
    "\n",
    "feature_name = kalman_df.columns.to_list()\n",
    "feature_name = ['answer_text', 'hr_average', 'rmssd']\n",
    "feature_name = list(filter(lambda item: \"user\" not in item.lower() and \"date\" not in item.lower() and \"X\" != item, feature_name))\n",
    "print(feature_name)\n",
    "\n",
    "# window_select(kalman_df, feature_name, ADFTestResultRetriver(kalman_df, feature_name))\n",
    "# window_select(kalman_df, feature_name, ADFSingleWindowSelector(kalman_df, feature_name))\n",
    "window_select(kalman_df, feature_name, ACFSingleWindowSelector(kalman_df, feature_name, method='avg'), minimal_window_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def window_select_acf(df, features):\n",
    "#     acfs = []\n",
    "#     for feature in features:\n",
    "#         series = df[feature]\n",
    "#         acfs.append(torch.abs(torch.Tensor(acf(series, nlags=len(series) - 1))))\n",
    "#     print(acfs)\n",
    "# window_select_acf(kalman_df, feature_name)\n",
    "def get_acf_list(df, features, start_window, curr_window_size):\n",
    "    acf_value_list = []\n",
    "    for feature in features:\n",
    "        series = df[start_window:][feature]\n",
    "        acf_values = torch.abs(torch.Tensor(acf(series, nlags=len(series) - 1)))\n",
    "        print(acf_values)\n",
    "        \n",
    "        acf_value_list.append(acf_values[:curr_window_size])\n",
    "    acf_value_list = torch.stack(acf_value_list)\n",
    "    print(acf_value_list.shape)\n",
    "    print(torch.min(acf_value_list, axis=0)[0])\n",
    "    return acf_value_list\n",
    "# def window_select(df, features, minimal_window_size=7, get_value_list=get_acf_list, constraint_test=):\n",
    "#     curr_window_size = minimal_window_size\n",
    "#     total_len = len(df)\n",
    "#     start_window = 0\n",
    "#     p_value_list = []\n",
    "#     break_points = []\n",
    "#     while start_window + curr_window_size < total_len:\n",
    "#         p_value_list = get_value_list(df, features, start_window, curr_window_size)\n",
    "#         constraint_satisfied = constraint_test(p_value_list, \"avg\")\n",
    "#         if not constraint_satisfied:\n",
    "#             break_points.append(start_window)\n",
    "#             start_window = start_window + curr_window_size\n",
    "#             curr_window_size = minimal_window_size\n",
    "#         else:\n",
    "#             curr_window_size += 1\n",
    "#     return break_points\n",
    "get_acf_list(kalman_df, ['hr_average', 'rmssd'], 0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acf_list(kalman_df, ['hr_average'], 14, len(kalman_df)-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value_constraint_test(p_value_list, method=\"max\"):\n",
    "    if method == \"max\":\n",
    "        max_p_value = max(p_value_list)\n",
    "        print(p_value_list)\n",
    "        return max_p_value <= 0.05\n",
    "    if method == \"avg\":\n",
    "        print(np.mean(p_value_list))\n",
    "        return np.mean(p_value_list) <= 0.05\n",
    "\n",
    "def get_p_value_list(df, features, start_window, curr_window_size)\n",
    "    p_value_list = []\n",
    "    for feature in features:\n",
    "        series = df[start_window:start_window+curr_window_size][feature]\n",
    "        p_value = adfuller(series, autolag='AIC')[1]\n",
    "        p_value_list.append(p_value)\n",
    "    return p_value_list\n",
    "    \n",
    "def window_select_adf(df, features):\n",
    "    minimal_window_size = 7\n",
    "    curr_window_size = minimal_window_size\n",
    "    total_len = len(df)\n",
    "    start_window = 0\n",
    "    p_value_list = []\n",
    "    break_points = []\n",
    "    while start_window + curr_window_size < total_len:\n",
    "        p_value_list = get_p_value_list(df, features, start_window, curr_window_size)\n",
    "        constraint_satisfied = p_value_constraint_test(p_value_list, \"avg\")\n",
    "        if not constraint_satisfied:\n",
    "            break_points.append(start_window)\n",
    "            start_window = start_window + curr_window_size\n",
    "            curr_window_size = minimal_window_size\n",
    "        else:\n",
    "            curr_window_size += 1\n",
    "    return break_points\n",
    "window_select_adf(kalman_df, feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv('./imputed_df_sleep_fatigue/mean_impute_df_userid_1032.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_test(series):\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'n_lags: {result[1]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    for key, value in result[4].items():\n",
    "        print('Critial Values:')\n",
    "        print(f'   {key}, {value}')\n",
    "\n",
    "\n",
    "stationary_test(kalman_df[0:8]['answer_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_test(kalman_df['hr_average'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_test(kalman_df['breath_average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_test(kalman_df['rmssd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_test(mean_df['answer_text'])\n",
    "stationary_test(mean_df['rmssd'])\n",
    "stationary_test(mean_df['breath_average'])\n",
    "stationary_test(mean_df['hr_average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/domino/datasets/local/Bump/mice_user_42.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import math\n",
    "import seaborn as sns; sns.set()\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "class TNCDataset(data.Dataset):\n",
    "    def __init__(self, x, mc_sample_size, window_size, augmentation, epsilon=3, state=None, adf=False):\n",
    "        super(TNCDataset, self).__init__()\n",
    "        self.time_series = x\n",
    "        self.T = x.shape[-1]\n",
    "        self.window_size = window_size\n",
    "        self.sliding_gap = int(window_size*25.2)\n",
    "        self.window_per_sample = (self.T-2*self.window_size)//self.sliding_gap\n",
    "        self.mc_sample_size = mc_sample_size\n",
    "        self.state = state\n",
    "        self.augmentation = augmentation\n",
    "        self.adf = adf\n",
    "        if not self.adf:\n",
    "            self.epsilon = epsilon\n",
    "            self.delta = 5*window_size*epsilon\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_series)*self.augmentation\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        ind = ind%len(self.time_series)\n",
    "        print(2*self.window_size)\n",
    "        print(self.T-2*self.window_size)\n",
    "        t = np.random.randint(2*self.window_size, self.T-2*self.window_size)\n",
    "        \n",
    "        x_t = self.time_series[ind][:,t-self.window_size//2:t+self.window_size//2]\n",
    "        plt.savefig('./plots/%s_seasonal.png'%ind)\n",
    "        X_close = self._find_neighours(self.time_series[ind], t)\n",
    "        X_distant = self._find_non_neighours(self.time_series[ind], t)\n",
    "\n",
    "        if self.state is None:\n",
    "            y_t = -1\n",
    "        else:\n",
    "            y_t = torch.round(torch.mean(self.state[ind][t-self.window_size//2:t+self.window_size//2]))\n",
    "        return x_t, X_close, X_distant, y_t\n",
    "\n",
    "    def _find_neighours(self, x, t):\n",
    "        T = self.time_series.shape[-1]\n",
    "        if self.adf:\n",
    "            gap = self.window_size\n",
    "            corr = []\n",
    "            for w_t in range(self.window_size,4*self.window_size, gap):\n",
    "                try:\n",
    "                    p_val = 0\n",
    "                    for f in range(x.shape[-2]):\n",
    "                        p = adfuller(np.array(x[f, max(0,t - w_t):min(x.shape[-1], t + w_t)].reshape(-1, )))[1]\n",
    "                        p_val += 0.01 if math.isnan(p) else p\n",
    "                    corr.append(p_val/x.shape[-2])\n",
    "                except:\n",
    "                    corr.append(0.6)\n",
    "            self.epsilon = len(corr) if len(np.where(np.array(corr) >= 0.01)[0])==0 else (np.where(np.array(corr) >= 0.01)[0][0] + 1)\n",
    "            self.delta = 5*self.epsilon*self.window_size\n",
    "\n",
    "        ## Random from a Gaussian\n",
    "        t_p = [int(t+np.random.randn()*self.epsilon*self.window_size) for _ in range(self.mc_sample_size)]\n",
    "        t_p = [max(self.window_size//2+1,min(t_pp,T-self.window_size//2)) for t_pp in t_p]\n",
    "        x_p = torch.stack([x[:, t_ind-self.window_size//2:t_ind+self.window_size//2] for t_ind in t_p])\n",
    "        return x_p\n",
    "\n",
    "    def _find_non_neighours(self, x, t):\n",
    "        T = self.time_series.shape[-1]\n",
    "        if t>T/2:\n",
    "            t_n = np.random.randint(self.window_size//2, max((t - self.delta + 1), self.window_size//2+1), self.mc_sample_size)\n",
    "        else:\n",
    "            t_n = np.random.randint(min((t + self.delta), (T - self.window_size-1)), (T - self.window_size//2), self.mc_sample_size)\n",
    "        x_n = torch.stack([x[:, t_ind-self.window_size//2:t_ind+self.window_size//2] for t_ind in t_n])\n",
    "\n",
    "        if len(x_n)==0:\n",
    "            rand_t = np.random.randint(0,self.window_size//5)\n",
    "            if t > T / 2:\n",
    "                x_n = x[:,rand_t:rand_t+self.window_size].unsqueeze(0)\n",
    "            else:\n",
    "                x_n = x[:, T - rand_t - self.window_size:T - rand_t].unsqueeze(0)\n",
    "        return x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "kalman_df = pd.read_csv('./imputed_df_sleep_fatigue/kalman_impute_df_userid_1032.csv')\n",
    "kalman_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = kalman_df[['hr_average', 'rmssd']]\n",
    "ds = ds.to_numpy()\n",
    "ds = ds.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = TNCDataset(ds, mc_sample_size=20, window_size=7, augmentation=1, adf=True)\n",
    "mydataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-r2ty3snk because the default path (/home/ubuntu/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import io\n",
    "from io import StringIO, BytesIO, TextIOWrapper\n",
    "import gzip\n",
    "from datetime import datetime, date\n",
    "from s3_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import ast\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from statsmodels.tsa.stattools import adfuller, acf\n",
    "from utils import *\n",
    "from src.stationary_test_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['answer_text', 'hr_average', 'rmssd']\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219,\n        0.7152])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219,\n        0.7152, 0.6966])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219,\n        0.7152, 0.6966, 0.6846])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219,\n        0.7152, 0.6966, 0.6846, 0.6707])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219,\n        0.7152, 0.6966, 0.6846, 0.6707, 0.6576])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219,\n        0.7152, 0.6966, 0.6846, 0.6707, 0.6576, 0.6236])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219,\n        0.7152, 0.6966, 0.6846, 0.6707, 0.6576, 0.6236, 0.6239])\ntensor([1.0000, 0.8726, 0.8414, 0.8241, 0.8087, 0.7671, 0.7598, 0.7333, 0.7219,\n        0.7152, 0.6966, 0.6846, 0.6707, 0.6576, 0.6236, 0.6239, 0.5999])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152,\n        0.7056])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152,\n        0.7056, 0.6893])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152,\n        0.7056, 0.6893, 0.6754])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152,\n        0.7056, 0.6893, 0.6754, 0.6582])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152,\n        0.7056, 0.6893, 0.6754, 0.6582, 0.6447])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152,\n        0.7056, 0.6893, 0.6754, 0.6582, 0.6447, 0.6091])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152,\n        0.7056, 0.6893, 0.6754, 0.6582, 0.6447, 0.6091, 0.6083])\ntensor([1.0000, 0.8762, 0.8433, 0.8230, 0.8082, 0.7652, 0.7577, 0.7304, 0.7152,\n        0.7056, 0.6893, 0.6754, 0.6582, 0.6447, 0.6091, 0.6083, 0.5834])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147, 0.7011])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147, 0.7011, 0.6877])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147, 0.7011, 0.6877, 0.6749])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147, 0.7011, 0.6877, 0.6749, 0.6590])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147, 0.7011, 0.6877, 0.6749, 0.6590, 0.6272])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147, 0.7011, 0.6877, 0.6749, 0.6590, 0.6272, 0.6301])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147, 0.7011, 0.6877, 0.6749, 0.6590, 0.6272, 0.6301, 0.6060])\ntensor([1.0000, 0.8776, 0.8461, 0.8269, 0.8114, 0.7689, 0.7638, 0.7366, 0.7226,\n        0.7147, 0.7011, 0.6877, 0.6749, 0.6590, 0.6272, 0.6301, 0.6060, 0.5913])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195, 0.7036])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195, 0.7036, 0.6895])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195, 0.7036, 0.6895, 0.6767])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195, 0.7036, 0.6895, 0.6767, 0.6590])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195, 0.7036, 0.6895, 0.6767, 0.6590, 0.6282])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195, 0.7036, 0.6895, 0.6767, 0.6590, 0.6282, 0.6315])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195, 0.7036, 0.6895, 0.6767, 0.6590, 0.6282, 0.6315, 0.6060])\ntensor([1.0000, 0.8841, 0.8524, 0.8314, 0.8155, 0.7754, 0.7696, 0.7426, 0.7256,\n        0.7195, 0.7036, 0.6895, 0.6767, 0.6590, 0.6282, 0.6315, 0.6060, 0.5907])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247, 0.7064])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247, 0.7064, 0.6895])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247, 0.7064, 0.6895, 0.6795])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247, 0.7064, 0.6895, 0.6795, 0.6603])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247, 0.7064, 0.6895, 0.6795, 0.6603, 0.6295])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247, 0.7064, 0.6895, 0.6795, 0.6603, 0.6295, 0.6335])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247, 0.7064, 0.6895, 0.6795, 0.6603, 0.6295, 0.6335, 0.6076])\ntensor([1.0000, 0.8867, 0.8589, 0.8408, 0.8233, 0.7810, 0.7762, 0.7501, 0.7319,\n        0.7247, 0.7064, 0.6895, 0.6795, 0.6603, 0.6295, 0.6335, 0.6076, 0.5935])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270,\n        0.7183])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270,\n        0.7183, 0.6997])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270,\n        0.7183, 0.6997, 0.6821])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270,\n        0.7183, 0.6997, 0.6821, 0.6708])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270,\n        0.7183, 0.6997, 0.6821, 0.6708, 0.6512])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270,\n        0.7183, 0.6997, 0.6821, 0.6708, 0.6512, 0.6198])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270,\n        0.7183, 0.6997, 0.6821, 0.6708, 0.6512, 0.6198, 0.6235])\ntensor([1.0000, 0.8906, 0.8592, 0.8379, 0.8206, 0.7765, 0.7716, 0.7438, 0.7270,\n        0.7183, 0.6997, 0.6821, 0.6708, 0.6512, 0.6198, 0.6235, 0.5967])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563, 0.7286])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563, 0.7286, 0.7118])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563, 0.7286, 0.7118,\n        0.7014])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563, 0.7286, 0.7118,\n        0.7014, 0.6837])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563, 0.7286, 0.7118,\n        0.7014, 0.6837, 0.6643])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563, 0.7286, 0.7118,\n        0.7014, 0.6837, 0.6643, 0.6511])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563, 0.7286, 0.7118,\n        0.7014, 0.6837, 0.6643, 0.6511, 0.6300])\ntensor([1.0000, 0.8845, 0.8511, 0.8261, 0.8092, 0.7623, 0.7563, 0.7286, 0.7118,\n        0.7014, 0.6837, 0.6643, 0.6511, 0.6300, 0.5978])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417, 0.7344])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417, 0.7344, 0.7069])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417, 0.7344, 0.7069, 0.6901])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417, 0.7344, 0.7069, 0.6901,\n        0.6783])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417, 0.7344, 0.7069, 0.6901,\n        0.6783, 0.6591])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417, 0.7344, 0.7069, 0.6901,\n        0.6783, 0.6591, 0.6379])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417, 0.7344, 0.7069, 0.6901,\n        0.6783, 0.6591, 0.6379, 0.6221])\ntensor([1.0000, 0.8744, 0.8379, 0.8098, 0.7927, 0.7417, 0.7344, 0.7069, 0.6901,\n        0.6783, 0.6591, 0.6379, 0.6221, 0.5975])\ntensor([1.0000, 0.8597, 0.8188, 0.7817, 0.7636])\ntensor([1.0000, 0.8597, 0.8188, 0.7817, 0.7636, 0.7059])\ntensor([1.0000, 0.8597, 0.8188, 0.7817, 0.7636, 0.7059, 0.6941])\ntensor([1.0000, 0.8597, 0.8188, 0.7817, 0.7636, 0.7059, 0.6941, 0.6652])\ntensor([1.0000, 0.8597, 0.8188, 0.7817, 0.7636, 0.7059, 0.6941, 0.6652, 0.6491])\ntensor([1.0000, 0.8597, 0.8188, 0.7817, 0.7636, 0.7059, 0.6941, 0.6652, 0.6491,\n        0.6320])\ntensor([1.0000, 0.8597, 0.8188, 0.7817, 0.7636, 0.7059, 0.6941, 0.6652, 0.6491,\n        0.6320, 0.6090])\ntensor([1.0000, 0.8597, 0.8188, 0.7817, 0.7636, 0.7059, 0.6941, 0.6652, 0.6491,\n        0.6320, 0.6090, 0.5845])\ntensor([1.0000, 0.8101, 0.7628, 0.7175, 0.7104])\ntensor([1.0000, 0.8101, 0.7628, 0.7175, 0.7104, 0.6408])\ntensor([1.0000, 0.8101, 0.7628, 0.7175, 0.7104, 0.6408, 0.6296])\ntensor([1.0000, 0.8101, 0.7628, 0.7175, 0.7104, 0.6408, 0.6296, 0.5908])\ntensor([1.0000, 0.7510, 0.7136, 0.6464, 0.6390])\ntensor([1.0000, 0.7510, 0.7136, 0.6464, 0.6390, 0.5663])\ntensor([1.0000, 0.7316, 0.7238, 0.6257, 0.6323])\ntensor([1.0000, 0.7316, 0.7238, 0.6257, 0.6323, 0.5558])\ntensor([1.0000, 0.7186, 0.7259, 0.6271, 0.6377])\ntensor([1.0000, 0.7186, 0.7259, 0.6271, 0.6377, 0.5489])\ntensor([1.0000, 0.6667, 0.6690, 0.5610, 0.5831])\ntensor([1.0000, 0.5876, 0.6281, 0.5139, 0.5557])\ntensor([1.0000, 0.6107, 0.5994, 0.4999, 0.5383])\ntensor([1.0000, 0.5965, 0.5758, 0.4887, 0.4981])\ntensor([1.0000, 0.5462, 0.5368, 0.5064, 0.4680])\ntensor([1.0000, 0.5265, 0.5096, 0.4839, 0.4411])\ntensor([1.0000, 0.5050, 0.4885, 0.4457, 0.4146])\ntensor([1.0000, 0.4719, 0.4479, 0.3919, 0.3530])\ntensor([1.0000, 0.4311, 0.3990, 0.3314, 0.2631])\ntensor([1.0000, 0.4159, 0.3308, 0.2515, 0.1617])\ntensor([1.0000, 0.3354, 0.2486, 0.1922, 0.1586])\ntensor([1.0000, 0.3276, 0.2338, 0.1835, 0.1607])\ntensor([1.0000, 0.2783, 0.1975, 0.2440, 0.2606])\ntensor([1.0000, 0.2780, 0.2077, 0.2502, 0.2429])\ntensor([1.0000, 0.2609, 0.1924, 0.2109, 0.1998])\ntensor([1.0000, 0.2315, 0.1259, 0.2419, 0.1860])\ntensor([1.0000, 0.2280, 0.1220, 0.2593, 0.2026])\ntensor([1.0000, 0.2996, 0.2765, 0.3178, 0.1810])\ntensor([1.0000, 0.2735, 0.2016, 0.2118, 0.0610])\ntensor([1.0000, 0.1698, 0.1309, 0.1280, 0.1866])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0,\n 17,\n 34,\n 52,\n 70,\n 88,\n 105,\n 120,\n 134,\n 146,\n 154,\n 160,\n 166,\n 172,\n 177,\n 182,\n 187,\n 192,\n 197,\n 202,\n 207,\n 212,\n 217,\n 222,\n 227,\n 232,\n 237,\n 242,\n 247,\n 252,\n 257,\n 262,\n 267]"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "\n",
    "kalman_df = pd.read_csv('./imputed_df_sleep_fatigue/kalman_impute_df_userid_1032.csv')\n",
    "\n",
    "feature_name = kalman_df.columns.to_list()\n",
    "feature_name = ['answer_text', 'hr_average', 'rmssd']\n",
    "feature_name = list(filter(lambda item: \"user\" not in item.lower() and \"date\" not in item.lower() and \"X\" != item, feature_name))\n",
    "print(feature_name)\n",
    "\n",
    "# window_select(kalman_df, feature_name, ADFTestResultRetriver(kalman_df, feature_name))\n",
    "# window_select(kalman_df, feature_name, ADFSingleWindowSelector(kalman_df, feature_name))\n",
    "window_select(kalman_df, feature_name, ACFSingleWindowSelector(kalman_df, feature_name, method='avg'), minimal_window_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1.0000e+00, 8.5175e-01, 8.1481e-01, 7.9606e-01, 7.8889e-01, 7.3159e-01,\n        7.2643e-01, 6.8678e-01, 6.5974e-01, 6.5286e-01, 6.4287e-01, 6.2317e-01,\n        6.0399e-01, 5.9053e-01, 5.4583e-01, 5.5083e-01, 5.2000e-01, 5.0247e-01,\n        4.6967e-01, 4.6307e-01, 4.4055e-01, 4.4246e-01, 4.4823e-01, 4.3267e-01,\n        4.1963e-01, 4.0559e-01, 3.9653e-01, 3.9212e-01, 3.9727e-01, 3.7030e-01,\n        3.7321e-01, 3.5807e-01, 3.4900e-01, 3.1757e-01, 3.2717e-01, 3.0114e-01,\n        2.6316e-01, 2.5477e-01, 2.2896e-01, 1.9166e-01, 1.5985e-01, 1.5403e-01,\n        1.3093e-01, 1.2265e-01, 1.0882e-01, 1.0852e-01, 7.1664e-02, 5.7222e-02,\n        3.3970e-02, 1.3026e-02, 1.2210e-02, 2.1719e-02, 3.0477e-02, 5.3914e-02,\n        7.1800e-02, 7.7969e-02, 8.7914e-02, 1.0586e-01, 1.0597e-01, 1.1436e-01,\n        1.2249e-01, 1.3623e-01, 1.4587e-01, 1.6690e-01, 1.7410e-01, 1.7899e-01,\n        2.0328e-01, 2.0536e-01, 2.0741e-01, 2.1715e-01, 2.3208e-01, 2.3748e-01,\n        2.4080e-01, 2.4407e-01, 2.5194e-01, 2.5420e-01, 2.7061e-01, 2.7102e-01,\n        2.7466e-01, 2.7292e-01, 2.8155e-01, 2.8095e-01, 2.7695e-01, 2.7720e-01,\n        2.8977e-01, 2.8337e-01, 2.8995e-01, 2.8316e-01, 2.8888e-01, 2.8695e-01,\n        2.9188e-01, 3.0555e-01, 3.0759e-01, 3.0383e-01, 3.0747e-01, 3.2870e-01,\n        3.0897e-01, 2.9995e-01, 3.0153e-01, 3.0359e-01, 2.8720e-01, 3.0248e-01,\n        2.9534e-01, 2.9360e-01, 2.9262e-01, 3.0561e-01, 2.9658e-01, 3.0063e-01,\n        3.0653e-01, 2.9327e-01, 2.9913e-01, 3.0855e-01, 3.0281e-01, 2.9520e-01,\n        3.0567e-01, 3.0437e-01, 3.0223e-01, 2.9064e-01, 2.9815e-01, 2.9385e-01,\n        2.8775e-01, 2.9257e-01, 2.9714e-01, 2.9562e-01, 2.8720e-01, 2.8240e-01,\n        2.8018e-01, 2.6784e-01, 2.4550e-01, 2.5339e-01, 2.4932e-01, 2.3608e-01,\n        2.2649e-01, 2.3146e-01, 2.2759e-01, 2.1409e-01, 2.2760e-01, 2.1886e-01,\n        2.1539e-01, 2.2160e-01, 2.2647e-01, 2.0991e-01, 2.1526e-01, 2.0879e-01,\n        2.1056e-01, 2.0520e-01, 2.0673e-01, 1.9862e-01, 1.9225e-01, 1.9160e-01,\n        1.8234e-01, 1.7792e-01, 1.6411e-01, 1.6413e-01, 1.4558e-01, 1.4224e-01,\n        1.3254e-01, 1.2136e-01, 1.0871e-01, 1.0309e-01, 8.8324e-02, 8.0667e-02,\n        6.8597e-02, 6.7285e-02, 6.8867e-02, 6.4315e-02, 7.4050e-02, 6.7896e-02,\n        7.9239e-02, 6.5048e-02, 7.2633e-02, 6.6917e-02, 6.1207e-02, 5.1437e-02,\n        6.8513e-02, 5.7908e-02, 6.9781e-02, 7.3778e-02, 7.5649e-02, 6.6104e-02,\n        7.2765e-02, 6.7705e-02, 5.5602e-02, 4.9673e-02, 3.8750e-02, 3.2135e-02,\n        1.9188e-02, 5.1289e-03, 3.1592e-03, 7.1785e-05, 1.6805e-02, 1.9390e-02,\n        2.4065e-02, 3.0241e-02, 4.4967e-02, 5.6374e-02, 7.9237e-02, 8.8425e-02,\n        8.5507e-02, 9.6978e-02, 9.9438e-02, 9.7159e-02, 9.7245e-02, 9.8917e-02,\n        9.1355e-02, 9.7696e-02, 1.0240e-01, 1.0408e-01, 9.3223e-02, 1.0291e-01,\n        1.0388e-01, 8.6143e-02, 8.2398e-02, 8.3010e-02, 8.4293e-02, 7.9618e-02,\n        8.9616e-02, 9.5630e-02, 1.0517e-01, 1.0078e-01, 1.1113e-01, 1.2140e-01,\n        1.1615e-01, 9.8814e-02, 1.0862e-01, 1.0741e-01, 1.1224e-01, 1.0927e-01,\n        1.0343e-01, 1.0765e-01, 1.2032e-01, 1.2434e-01, 1.1895e-01, 1.2368e-01,\n        1.2433e-01, 1.2423e-01, 1.1259e-01, 1.1626e-01, 1.0502e-01, 1.0696e-01,\n        1.0694e-01, 1.0433e-01, 1.0271e-01, 1.0527e-01, 9.7281e-02, 8.9202e-02,\n        8.5763e-02, 8.4239e-02, 8.5347e-02, 8.0260e-02, 6.5544e-02, 6.3556e-02,\n        7.9541e-02, 5.8653e-02, 5.4587e-02, 5.0402e-02, 5.0517e-02, 3.4905e-02,\n        4.1035e-02, 2.9329e-02, 2.6552e-02, 3.0056e-02, 2.3234e-02, 1.8533e-02,\n        2.1598e-02, 1.5340e-02, 6.6566e-03, 1.1962e-02, 8.3650e-03, 8.0523e-03,\n        4.8446e-03, 4.4429e-03, 3.7354e-03, 3.4804e-03, 1.2852e-03, 4.6822e-04])\ntensor([1.0000e+00, 8.8007e-01, 8.3695e-01, 8.2827e-01, 7.9697e-01, 7.4188e-01,\n        7.3440e-01, 6.8598e-01, 6.7278e-01, 6.7875e-01, 6.3595e-01, 6.2217e-01,\n        6.3109e-01, 6.0409e-01, 5.6407e-01, 5.6314e-01, 5.2815e-01, 5.1522e-01,\n        4.8504e-01, 4.8240e-01, 4.6095e-01, 4.6470e-01, 4.5484e-01, 4.4395e-01,\n        4.2577e-01, 4.0797e-01, 3.9572e-01, 3.7514e-01, 3.7519e-01, 3.5546e-01,\n        3.5219e-01, 3.4496e-01, 3.4765e-01, 3.2377e-01, 3.2786e-01, 3.1953e-01,\n        2.9748e-01, 2.7477e-01, 2.5747e-01, 2.1450e-01, 1.8620e-01, 1.5814e-01,\n        1.3547e-01, 1.1821e-01, 1.0175e-01, 8.9805e-02, 6.7151e-02, 6.2453e-02,\n        3.8708e-02, 2.3608e-02, 6.8653e-03, 4.5116e-04, 1.2002e-02, 2.3386e-02,\n        3.4059e-02, 4.3453e-02, 5.0865e-02, 5.8215e-02, 6.6548e-02, 7.1884e-02,\n        7.9397e-02, 8.3548e-02, 8.9002e-02, 1.0162e-01, 1.0376e-01, 1.0952e-01,\n        1.1996e-01, 1.2332e-01, 1.2762e-01, 1.3814e-01, 1.4046e-01, 1.4791e-01,\n        1.5681e-01, 1.5581e-01, 1.6062e-01, 1.6969e-01, 1.7472e-01, 1.7636e-01,\n        1.8364e-01, 1.8406e-01, 1.8858e-01, 1.9371e-01, 1.9499e-01, 1.9936e-01,\n        2.0830e-01, 2.0939e-01, 2.1288e-01, 2.1646e-01, 2.2005e-01, 2.1860e-01,\n        2.2618e-01, 2.2789e-01, 2.3001e-01, 2.3494e-01, 2.3826e-01, 2.4377e-01,\n        2.4234e-01, 2.4669e-01, 2.4954e-01, 2.5078e-01, 2.5202e-01, 2.5588e-01,\n        2.5791e-01, 2.5957e-01, 2.6433e-01, 2.6496e-01, 2.6943e-01, 2.7181e-01,\n        2.7276e-01, 2.7595e-01, 2.8133e-01, 2.8195e-01, 2.8600e-01, 2.8475e-01,\n        2.8795e-01, 2.9105e-01, 2.9257e-01, 2.9175e-01, 2.9497e-01, 2.9568e-01,\n        2.9604e-01, 2.9722e-01, 2.9671e-01, 2.9864e-01, 2.9788e-01, 2.9512e-01,\n        2.9340e-01, 2.9332e-01, 2.9002e-01, 2.8888e-01, 2.9101e-01, 2.8553e-01,\n        2.8777e-01, 2.8849e-01, 2.9114e-01, 2.8658e-01, 2.9130e-01, 2.9116e-01,\n        2.8885e-01, 2.8928e-01, 2.9170e-01, 2.8459e-01, 2.8740e-01, 2.8599e-01,\n        2.8720e-01, 2.8562e-01, 2.8643e-01, 2.8129e-01, 2.7847e-01, 2.8070e-01,\n        2.7155e-01, 2.7283e-01, 2.6756e-01, 2.6433e-01, 2.5906e-01, 2.5754e-01,\n        2.4791e-01, 2.3802e-01, 2.2890e-01, 2.2247e-01, 2.1135e-01, 2.0104e-01,\n        1.9742e-01, 1.9172e-01, 1.9832e-01, 2.0114e-01, 2.0253e-01, 1.9648e-01,\n        2.0200e-01, 1.9094e-01, 1.9394e-01, 1.8888e-01, 1.7973e-01, 1.6843e-01,\n        1.7942e-01, 1.7818e-01, 1.8095e-01, 1.8302e-01, 1.7143e-01, 1.6984e-01,\n        1.6689e-01, 1.5916e-01, 1.4032e-01, 1.3444e-01, 1.2531e-01, 1.1502e-01,\n        1.0905e-01, 1.0290e-01, 1.0104e-01, 1.0204e-01, 8.2289e-02, 7.3609e-02,\n        6.1756e-02, 4.4890e-02, 2.3458e-02, 1.7993e-04, 2.1141e-02, 3.3687e-02,\n        3.6440e-02, 4.9653e-02, 4.7617e-02, 5.0153e-02, 4.9625e-02, 5.1791e-02,\n        5.1791e-02, 6.0948e-02, 6.1475e-02, 7.0106e-02, 7.2116e-02, 8.0979e-02,\n        8.7088e-02, 8.6298e-02, 8.6513e-02, 1.0069e-01, 1.1587e-01, 1.1733e-01,\n        1.2992e-01, 1.3631e-01, 1.5108e-01, 1.4027e-01, 1.5895e-01, 1.5569e-01,\n        1.5830e-01, 1.5143e-01, 1.5740e-01, 1.5544e-01, 1.6451e-01, 1.6638e-01,\n        1.6216e-01, 1.6176e-01, 1.7857e-01, 1.8520e-01, 1.8393e-01, 1.8939e-01,\n        1.9869e-01, 2.0401e-01, 1.8646e-01, 1.8867e-01, 1.7732e-01, 1.8749e-01,\n        1.8195e-01, 1.7380e-01, 1.6808e-01, 1.7884e-01, 1.6680e-01, 1.5087e-01,\n        1.5961e-01, 1.5794e-01, 1.5123e-01, 1.4869e-01, 1.3719e-01, 1.2462e-01,\n        1.4106e-01, 1.1993e-01, 1.0474e-01, 1.0982e-01, 1.0167e-01, 7.6089e-02,\n        8.1965e-02, 6.5553e-02, 5.7506e-02, 6.1129e-02, 4.9289e-02, 3.7854e-02,\n        3.9422e-02, 2.7568e-02, 1.4905e-02, 1.9184e-02, 1.2635e-02, 1.0675e-02,\n        9.7643e-03, 8.7909e-03, 5.8477e-03, 4.5617e-03, 1.4860e-03, 6.0421e-04])\ntorch.Size([2, 8])\ntensor([1.0000, 0.8518, 0.8148, 0.7961, 0.7889, 0.7316, 0.7264, 0.6860])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1.0000, 0.8518, 0.8148, 0.7961, 0.7889, 0.7316, 0.7264, 0.6868],\n        [1.0000, 0.8801, 0.8370, 0.8283, 0.7970, 0.7419, 0.7344, 0.6860]])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "\n",
    "# def window_select_acf(df, features):\n",
    "#     acfs = []\n",
    "#     for feature in features:\n",
    "#         series = df[feature]\n",
    "#         acfs.append(torch.abs(torch.Tensor(acf(series, nlags=len(series) - 1))))\n",
    "#     print(acfs)\n",
    "# window_select_acf(kalman_df, feature_name)\n",
    "def get_acf_list(df, features, start_window, curr_window_size):\n",
    "    acf_value_list = []\n",
    "    for feature in features:\n",
    "        series = df[start_window:][feature]\n",
    "        acf_values = torch.abs(torch.Tensor(acf(series, nlags=len(series) - 1)))\n",
    "        print(acf_values)\n",
    "        \n",
    "        acf_value_list.append(acf_values[:curr_window_size])\n",
    "    acf_value_list = torch.stack(acf_value_list)\n",
    "    print(acf_value_list.shape)\n",
    "    print(torch.min(acf_value_list, axis=0)[0])\n",
    "    return acf_value_list\n",
    "# def window_select(df, features, minimal_window_size=7, get_value_list=get_acf_list, constraint_test=):\n",
    "#     curr_window_size = minimal_window_size\n",
    "#     total_len = len(df)\n",
    "#     start_window = 0\n",
    "#     p_value_list = []\n",
    "#     break_points = []\n",
    "#     while start_window + curr_window_size < total_len:\n",
    "#         p_value_list = get_value_list(df, features, start_window, curr_window_size)\n",
    "#         constraint_satisfied = constraint_test(p_value_list, \"avg\")\n",
    "#         if not constraint_satisfied:\n",
    "#             break_points.append(start_window)\n",
    "#             start_window = start_window + curr_window_size\n",
    "#             curr_window_size = minimal_window_size\n",
    "#         else:\n",
    "#             curr_window_size += 1\n",
    "#     return break_points\n",
    "get_acf_list(kalman_df, ['hr_average', 'rmssd'], 0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "14    -0.622555\n15    -0.726196\n16     0.030387\n17    -0.683259\n18    -0.607749\n         ...   \n271   -0.011069\n272   -0.692142\n273   -1.879579\n274   -0.973455\n275   -1.071344\nName: hr_average, Length: 262, dtype: float64\ntensor([1.0000e+00, 8.5731e-01, 8.1870e-01, 7.9719e-01, 7.8947e-01, 7.3282e-01,\n        7.2565e-01, 6.8574e-01, 6.5756e-01, 6.4566e-01, 6.3891e-01, 6.1773e-01,\n        5.9675e-01, 5.8161e-01, 5.3389e-01, 5.3890e-01, 5.0802e-01, 4.8543e-01,\n        4.5364e-01, 4.4759e-01, 4.2414e-01, 4.2437e-01, 4.3630e-01, 4.2264e-01,\n        4.1106e-01, 3.9776e-01, 3.9000e-01, 3.8320e-01, 3.9097e-01, 3.6813e-01,\n        3.6749e-01, 3.5219e-01, 3.4618e-01, 3.1899e-01, 3.2575e-01, 3.0043e-01,\n        2.6461e-01, 2.5845e-01, 2.2802e-01, 1.9082e-01, 1.5812e-01, 1.5255e-01,\n        1.2167e-01, 1.1565e-01, 1.0191e-01, 1.0020e-01, 5.9692e-02, 4.5995e-02,\n        2.2092e-02, 5.7109e-04, 2.5222e-02, 4.1685e-02, 5.1007e-02, 7.4761e-02,\n        9.3351e-02, 1.0355e-01, 1.1124e-01, 1.3145e-01, 1.2777e-01, 1.3755e-01,\n        1.4348e-01, 1.5907e-01, 1.6885e-01, 1.8623e-01, 1.9174e-01, 1.9693e-01,\n        2.1977e-01, 2.2006e-01, 2.2075e-01, 2.2802e-01, 2.4302e-01, 2.4834e-01,\n        2.5166e-01, 2.5534e-01, 2.6045e-01, 2.6270e-01, 2.7982e-01, 2.7987e-01,\n        2.8207e-01, 2.8194e-01, 2.8987e-01, 2.9090e-01, 2.8813e-01, 2.8849e-01,\n        3.0138e-01, 2.9549e-01, 3.0141e-01, 2.9586e-01, 2.9939e-01, 2.9900e-01,\n        3.0008e-01, 3.1589e-01, 3.1691e-01, 3.0767e-01, 3.1172e-01, 3.3191e-01,\n        3.0817e-01, 3.0040e-01, 3.0393e-01, 3.0186e-01, 2.8590e-01, 2.9935e-01,\n        2.9227e-01, 2.8791e-01, 2.8863e-01, 3.0148e-01, 2.9352e-01, 2.9728e-01,\n        3.0408e-01, 2.9161e-01, 2.9691e-01, 3.0886e-01, 3.0158e-01, 2.9680e-01,\n        3.0759e-01, 3.0554e-01, 3.0218e-01, 2.9269e-01, 2.9493e-01, 2.9008e-01,\n        2.8295e-01, 2.8798e-01, 2.8498e-01, 2.8628e-01, 2.7830e-01, 2.7018e-01,\n        2.6760e-01, 2.5255e-01, 2.3068e-01, 2.3772e-01, 2.3394e-01, 2.2044e-01,\n        2.1171e-01, 2.1550e-01, 2.1158e-01, 1.9641e-01, 2.0983e-01, 1.9659e-01,\n        1.9428e-01, 2.0032e-01, 2.0210e-01, 1.8587e-01, 1.9270e-01, 1.8135e-01,\n        1.8342e-01, 1.7857e-01, 1.7702e-01, 1.6671e-01, 1.6272e-01, 1.6183e-01,\n        1.5111e-01, 1.4732e-01, 1.3870e-01, 1.3266e-01, 1.1391e-01, 1.2011e-01,\n        1.0386e-01, 9.1253e-02, 8.0416e-02, 7.7935e-02, 6.1034e-02, 5.2723e-02,\n        4.2461e-02, 3.9534e-02, 4.0764e-02, 3.7922e-02, 4.5932e-02, 3.9420e-02,\n        5.0309e-02, 3.6366e-02, 4.3910e-02, 3.7718e-02, 3.2514e-02, 2.3544e-02,\n        4.0515e-02, 2.8349e-02, 3.9419e-02, 4.1802e-02, 4.1949e-02, 3.4598e-02,\n        4.2371e-02, 3.5884e-02, 2.5162e-02, 1.7046e-02, 6.7817e-03, 8.0689e-04,\n        1.4468e-02, 2.4759e-02, 2.8963e-02, 2.9246e-02, 4.9907e-02, 5.2116e-02,\n        5.6745e-02, 6.0526e-02, 7.8676e-02, 9.2449e-02, 1.0865e-01, 1.2198e-01,\n        1.2027e-01, 1.2722e-01, 1.2591e-01, 1.2549e-01, 1.2214e-01, 1.2051e-01,\n        1.1167e-01, 1.2003e-01, 1.2314e-01, 1.2156e-01, 1.1255e-01, 1.1737e-01,\n        1.1667e-01, 9.0566e-02, 8.6939e-02, 7.9326e-02, 7.4888e-02, 6.3981e-02,\n        6.7734e-02, 6.5447e-02, 7.2008e-02, 6.5611e-02, 7.8671e-02, 9.0579e-02,\n        8.6670e-02, 7.1804e-02, 7.6978e-02, 8.2647e-02, 8.6719e-02, 9.0274e-02,\n        8.6334e-02, 8.9365e-02, 9.9869e-02, 1.1576e-01, 1.0793e-01, 1.1015e-01,\n        1.0898e-01, 1.1046e-01, 9.7930e-02, 1.0154e-01, 8.9016e-02, 8.8639e-02,\n        8.4737e-02, 7.8040e-02, 7.6528e-02, 8.2097e-02, 6.9704e-02, 5.8712e-02,\n        5.4589e-02, 5.2815e-02, 4.3150e-02, 3.7070e-02, 3.2367e-02, 2.3091e-02,\n        2.4854e-02, 1.8868e-02, 1.5072e-02, 1.6119e-02, 1.1861e-02, 6.4981e-03,\n        9.1928e-03, 6.7858e-03, 5.0939e-03, 2.4545e-03])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.0005710927653126419]"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "get_acf_list(kalman_df, ['hr_average'], 14, len(kalman_df)-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.286598960297648\n0.15402929498961349\n0.2913767916824355\n0.2524406503404044\n0.40178521691834196\n0.011192079549319773\n0.012969620760699222\n0.003351754032949019\n0.5725544825891805\n0.036827928578765726\n0.29952833859586636\n0.1332147126082648\n0.057255779287808464\n0.20654147278442192\n0.4965005482187161\nnan\n0.5204762331464731\n0.021695822526096923\n0.34832242386670764\n0.266926623476886\n0.19151155630601224\n0.04207608662146523\n0.21165043384009558\n0.2391273912853605\n0.09550138296179624\n0.36106412747877725\n0.20155621831218634\n0.4903157937909909\n0.1995571806641004\n0.19362458859964943\n0.32359038537230117\n0.27658826164246586\n0.3340869324498264\n0.13444619609614603\n0.14713316515500327\n0.6153007704759093\n0.48542488677551265\n0.46530968625125535\n0.3588906408532644\n0.282453791907525\n0.22632991960784973\n0.2331784517250295\n0.2004707997491829\n0.32134985791935555\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0,\n 7,\n 14,\n 21,\n 28,\n 35,\n 45,\n 53,\n 60,\n 67,\n 74,\n 81,\n 88,\n 95,\n 103,\n 110,\n 117,\n 125,\n 132,\n 139,\n 146,\n 153,\n 160,\n 167,\n 174,\n 181,\n 188,\n 195,\n 202,\n 209,\n 216,\n 223,\n 230,\n 237,\n 244,\n 251,\n 258,\n 265]"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "def p_value_constraint_test(p_value_list, method=\"max\"):\n",
    "    if method == \"max\":\n",
    "        max_p_value = max(p_value_list)\n",
    "        print(p_value_list)\n",
    "        return max_p_value <= 0.05\n",
    "    if method == \"avg\":\n",
    "        print(np.mean(p_value_list))\n",
    "        return np.mean(p_value_list) <= 0.05\n",
    "\n",
    "def get_p_value_list(df, features, start_window, curr_window_size)\n",
    "    p_value_list = []\n",
    "    for feature in features:\n",
    "        series = df[start_window:start_window+curr_window_size][feature]\n",
    "        p_value = adfuller(series, autolag='AIC')[1]\n",
    "        p_value_list.append(p_value)\n",
    "    return p_value_list\n",
    "    \n",
    "def window_select_adf(df, features):\n",
    "    minimal_window_size = 7\n",
    "    curr_window_size = minimal_window_size\n",
    "    total_len = len(df)\n",
    "    start_window = 0\n",
    "    p_value_list = []\n",
    "    break_points = []\n",
    "    while start_window + curr_window_size < total_len:\n",
    "        p_value_list = get_p_value_list(df, features, start_window, curr_window_size)\n",
    "        constraint_satisfied = p_value_constraint_test(p_value_list, \"avg\")\n",
    "        if not constraint_satisfied:\n",
    "            break_points.append(start_window)\n",
    "            start_window = start_window + curr_window_size\n",
    "            curr_window_size = minimal_window_size\n",
    "        else:\n",
    "            curr_window_size += 1\n",
    "    return break_points\n",
    "window_select_adf(kalman_df, feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv('./imputed_df_sleep_fatigue/mean_impute_df_userid_1032.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ADF Statistic: -0.5661920377856459\nn_lags: 0.8784397304792497\np-value: 0.8784397304792497\nCritial Values:\n   1%, -3.454988209954765\nCritial Values:\n   5%, -2.8723857312734613\nCritial Values:\n   10%, -2.572549407997327\n"
    }
   ],
   "source": [
    "def stationary_test(series):\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'n_lags: {result[1]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    for key, value in result[4].items():\n",
    "        print('Critial Values:')\n",
    "        print(f'   {key}, {value}')\n",
    "\n",
    "\n",
    "stationary_test(kalman_df[0:8]['answer_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ADF Statistic: -1.8575439563705518\nn_lags: 0.35228960159955947\np-value: 0.35228960159955947\nCritial Values:\n   1%, -3.4548039258751206\nCritial Values:\n   5%, -2.872304928618605\nCritial Values:\n   10%, -2.5725063100137175\n"
    }
   ],
   "source": [
    "stationary_test(kalman_df['hr_average'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ADF Statistic: -3.027035128956414\nn_lags: 0.03244563713705504\np-value: 0.03244563713705504\nCritial Values:\n   1%, -3.4548957220044336\nCritial Values:\n   5%, -2.8723451788613157\nCritial Values:\n   10%, -2.572527778361272\n"
    }
   ],
   "source": [
    "stationary_test(kalman_df['breath_average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ADF Statistic: -1.5314649203273019\nn_lags: 0.5178926730737616\np-value: 0.5178926730737616\nCritial Values:\n   1%, -3.4554613060274972\nCritial Values:\n   5%, -2.8725931472675046\nCritial Values:\n   10%, -2.5726600403359887\n"
    }
   ],
   "source": [
    "stationary_test(kalman_df['rmssd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ADF Statistic: -1.4913584583172514\nn_lags: 0.5377817724658496\np-value: 0.5377817724658496\nCritial Values:\n   1%, -3.4548957220044336\nCritial Values:\n   5%, -2.8723451788613157\nCritial Values:\n   10%, -2.572527778361272\nADF Statistic: -1.909395314682709\nn_lags: 0.3276542487032547\np-value: 0.3276542487032547\nCritial Values:\n   1%, -3.455365238788105\nCritial Values:\n   5%, -2.8725510317187024\nCritial Values:\n   10%, -2.5726375763314966\nADF Statistic: -3.1196408211122173\nn_lags: 0.025133413121681127\np-value: 0.025133413121681127\nCritial Values:\n   1%, -3.4548957220044336\nCritial Values:\n   5%, -2.8723451788613157\nCritial Values:\n   10%, -2.572527778361272\nADF Statistic: -2.5482957417772925\nn_lags: 0.10416113432665464\np-value: 0.10416113432665464\nCritial Values:\n   1%, -3.4546223782586534\nCritial Values:\n   5%, -2.8722253212300277\nCritial Values:\n   10%, -2.5724638500216264\n"
    }
   ],
   "source": [
    "stationary_test(mean_df['answer_text'])\n",
    "stationary_test(mean_df['rmssd'])\n",
    "stationary_test(mean_df['breath_average'])\n",
    "stationary_test(mean_df['hr_average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/domino/datasets/local/Bump/mice_user_42.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import math\n",
    "import seaborn as sns; sns.set()\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "class TNCDataset(data.Dataset):\n",
    "    def __init__(self, x, mc_sample_size, window_size, augmentation, epsilon=3, state=None, adf=False):\n",
    "        super(TNCDataset, self).__init__()\n",
    "        self.time_series = x\n",
    "        self.T = x.shape[-1]\n",
    "        self.window_size = window_size\n",
    "        self.sliding_gap = int(window_size*25.2)\n",
    "        self.window_per_sample = (self.T-2*self.window_size)//self.sliding_gap\n",
    "        self.mc_sample_size = mc_sample_size\n",
    "        self.state = state\n",
    "        self.augmentation = augmentation\n",
    "        self.adf = adf\n",
    "        if not self.adf:\n",
    "            self.epsilon = epsilon\n",
    "            self.delta = 5*window_size*epsilon\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_series)*self.augmentation\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        ind = ind%len(self.time_series)\n",
    "        print(2*self.window_size)\n",
    "        print(self.T-2*self.window_size)\n",
    "        t = np.random.randint(2*self.window_size, self.T-2*self.window_size)\n",
    "        \n",
    "        x_t = self.time_series[ind][:,t-self.window_size//2:t+self.window_size//2]\n",
    "        plt.savefig('./plots/%s_seasonal.png'%ind)\n",
    "        X_close = self._find_neighours(self.time_series[ind], t)\n",
    "        X_distant = self._find_non_neighours(self.time_series[ind], t)\n",
    "\n",
    "        if self.state is None:\n",
    "            y_t = -1\n",
    "        else:\n",
    "            y_t = torch.round(torch.mean(self.state[ind][t-self.window_size//2:t+self.window_size//2]))\n",
    "        return x_t, X_close, X_distant, y_t\n",
    "\n",
    "    def _find_neighours(self, x, t):\n",
    "        T = self.time_series.shape[-1]\n",
    "        if self.adf:\n",
    "            gap = self.window_size\n",
    "            corr = []\n",
    "            for w_t in range(self.window_size,4*self.window_size, gap):\n",
    "                try:\n",
    "                    p_val = 0\n",
    "                    for f in range(x.shape[-2]):\n",
    "                        p = adfuller(np.array(x[f, max(0,t - w_t):min(x.shape[-1], t + w_t)].reshape(-1, )))[1]\n",
    "                        p_val += 0.01 if math.isnan(p) else p\n",
    "                    corr.append(p_val/x.shape[-2])\n",
    "                except:\n",
    "                    corr.append(0.6)\n",
    "            self.epsilon = len(corr) if len(np.where(np.array(corr) >= 0.01)[0])==0 else (np.where(np.array(corr) >= 0.01)[0][0] + 1)\n",
    "            self.delta = 5*self.epsilon*self.window_size\n",
    "\n",
    "        ## Random from a Gaussian\n",
    "        t_p = [int(t+np.random.randn()*self.epsilon*self.window_size) for _ in range(self.mc_sample_size)]\n",
    "        t_p = [max(self.window_size//2+1,min(t_pp,T-self.window_size//2)) for t_pp in t_p]\n",
    "        x_p = torch.stack([x[:, t_ind-self.window_size//2:t_ind+self.window_size//2] for t_ind in t_p])\n",
    "        return x_p\n",
    "\n",
    "    def _find_non_neighours(self, x, t):\n",
    "        T = self.time_series.shape[-1]\n",
    "        if t>T/2:\n",
    "            t_n = np.random.randint(self.window_size//2, max((t - self.delta + 1), self.window_size//2+1), self.mc_sample_size)\n",
    "        else:\n",
    "            t_n = np.random.randint(min((t + self.delta), (T - self.window_size-1)), (T - self.window_size//2), self.mc_sample_size)\n",
    "        x_n = torch.stack([x[:, t_ind-self.window_size//2:t_ind+self.window_size//2] for t_ind in t_n])\n",
    "\n",
    "        if len(x_n)==0:\n",
    "            rand_t = np.random.randint(0,self.window_size//5)\n",
    "            if t > T / 2:\n",
    "                x_n = x[:,rand_t:rand_t+self.window_size].unsqueeze(0)\n",
    "            else:\n",
    "                x_n = x[:, T - rand_t - self.window_size:T - rand_t].unsqueeze(0)\n",
    "        return x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       X        date  user_id_x  answer_text  hr_average     rmssd  \\\n0      0  2021-10-25       1032     0.524594   -0.148764  0.225188   \n1      1  2021-10-26       1032     1.039473   -0.252406  0.404343   \n2      2  2021-10-27       1032     0.524594   -0.518913  0.897018   \n3      3  2021-10-28       1032     1.039473   -0.082138  0.449131   \n4      4  2021-10-29       1032     0.524594   -0.128036  0.449131   \n..   ...         ...        ...          ...         ...       ...   \n271  271  2022-07-11       1032     1.039473   -0.011069 -0.043545   \n272  272  2022-07-12       1032     1.039473   -0.692142  0.941807   \n273  273  2022-07-13       1032     1.039473   -1.879579  1.792793   \n274  274  2022-07-14       1032     1.039473   -0.973455  0.493920   \n275  275  2022-07-15       1032     1.039473   -1.071344  0.862914   \n\n     breath_average      score  user_id_y  birth_date  \n0          4.683366  76.000000       1032  2022-05-25  \n1          3.218078  75.000000       1032  2022-05-25  \n2          2.078409  89.000000       1032  2022-05-25  \n3          2.078409  83.000000       1032  2022-05-25  \n4          1.427170  77.000000       1032  2022-05-25  \n..              ...        ...        ...         ...  \n271       -0.038118  74.000000       1032  2022-05-25  \n272       -0.200928  88.000000       1032  2022-05-25  \n273       -1.177787  89.000000       1032  2022-05-25  \n274       -0.200928  90.000000       1032  2022-05-25  \n275       -0.380822  82.167529       1032  2022-05-25  \n\n[276 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>date</th>\n      <th>user_id_x</th>\n      <th>answer_text</th>\n      <th>hr_average</th>\n      <th>rmssd</th>\n      <th>breath_average</th>\n      <th>score</th>\n      <th>user_id_y</th>\n      <th>birth_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2021-10-25</td>\n      <td>1032</td>\n      <td>0.524594</td>\n      <td>-0.148764</td>\n      <td>0.225188</td>\n      <td>4.683366</td>\n      <td>76.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2021-10-26</td>\n      <td>1032</td>\n      <td>1.039473</td>\n      <td>-0.252406</td>\n      <td>0.404343</td>\n      <td>3.218078</td>\n      <td>75.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2021-10-27</td>\n      <td>1032</td>\n      <td>0.524594</td>\n      <td>-0.518913</td>\n      <td>0.897018</td>\n      <td>2.078409</td>\n      <td>89.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2021-10-28</td>\n      <td>1032</td>\n      <td>1.039473</td>\n      <td>-0.082138</td>\n      <td>0.449131</td>\n      <td>2.078409</td>\n      <td>83.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2021-10-29</td>\n      <td>1032</td>\n      <td>0.524594</td>\n      <td>-0.128036</td>\n      <td>0.449131</td>\n      <td>1.427170</td>\n      <td>77.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>271</td>\n      <td>2022-07-11</td>\n      <td>1032</td>\n      <td>1.039473</td>\n      <td>-0.011069</td>\n      <td>-0.043545</td>\n      <td>-0.038118</td>\n      <td>74.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>272</th>\n      <td>272</td>\n      <td>2022-07-12</td>\n      <td>1032</td>\n      <td>1.039473</td>\n      <td>-0.692142</td>\n      <td>0.941807</td>\n      <td>-0.200928</td>\n      <td>88.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>273</th>\n      <td>273</td>\n      <td>2022-07-13</td>\n      <td>1032</td>\n      <td>1.039473</td>\n      <td>-1.879579</td>\n      <td>1.792793</td>\n      <td>-1.177787</td>\n      <td>89.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>274</td>\n      <td>2022-07-14</td>\n      <td>1032</td>\n      <td>1.039473</td>\n      <td>-0.973455</td>\n      <td>0.493920</td>\n      <td>-0.200928</td>\n      <td>90.000000</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>275</td>\n      <td>2022-07-15</td>\n      <td>1032</td>\n      <td>1.039473</td>\n      <td>-1.071344</td>\n      <td>0.862914</td>\n      <td>-0.380822</td>\n      <td>82.167529</td>\n      <td>1032</td>\n      <td>2022-05-25</td>\n    </tr>\n  </tbody>\n</table>\n<p>276 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "kalman_df = pd.read_csv('./imputed_df_sleep_fatigue/kalman_impute_df_userid_1032.csv')\n",
    "kalman_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = kalman_df[['hr_average', 'rmssd']]\n",
    "ds = ds.to_numpy()\n",
    "ds = ds.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "14\n262\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m mydataset \u001b[38;5;241m=\u001b[39m TNCDataset(ds, mc_sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, augmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, adf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmydataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mTNCDataset.__getitem__\u001b[0;34m(self, ind)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[1;32m     38\u001b[0m t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[0;32m---> 40\u001b[0m x_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_series\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     41\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./plots/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_seasonal.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mind)\n\u001b[1;32m     42\u001b[0m X_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_neighours(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_series[ind], t)\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "mydataset = TNCDataset(ds, mc_sample_size=20, window_size=7, augmentation=1, adf=True)\n",
    "mydataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bittestvenvffa84736bc0f4a929f1714c5b83d5a1e",
   "display_name": "Python 3.6.10 64-bit ('test': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
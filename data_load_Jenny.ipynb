{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import io\n",
    "from io import StringIO, BytesIO, TextIOWrapper\n",
    "import gzip\n",
    "from datetime import datetime, date\n",
    "from s3_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import ast\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "import sys\n",
    "import time\n",
    "from utils import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define s3 bucket\n",
    "bucket = 'fouryouandme-study-data'\n",
    "\n",
    "#List s3 keys\n",
    "# get_matching_s3_keys(bucket, prefix='bump/') #Remove prefix to view non-BUMP data\n",
    "bucket = '4youandme-study-data' # for SinC project\n",
    "bucket = 'fouryouandme-study-data' # for 4YouandMe, Bump, CamCog or Bodyport project\n",
    "\n",
    "# prefix = {study_name} or {study_name}/{source}\n",
    "# sources: app_activities, bodyport, camcog, garmin, oura, redcap, rescuetime\n",
    "# note camcog not accessible to bodyport (and vice a versa)\n",
    "get_matching_s3_keys(bucket, prefix='bump/oura')\n",
    "key = 'bump/redcap/wave_4/study_ids.csv.gz'\n",
    "df_studyID = pandas_from_csv_s3(bucket, key=key, compression='gzip')\n",
    "\n",
    "# Some dataframes use 'record_id' instead of 'user_id'. \n",
    "# You'll need to match it up with df_studyID where'evidation_id' is 'user_id'\n",
    "# NOTE: Very few examples of this. Birthing data is the important one\n",
    "\n",
    "# Birthing Data\n",
    "key = 'bump/redcap/wave_4/birthing_data_cohort_2_only.csv.gz'\n",
    "df_birth = pandas_from_csv_s3(bucket, key=key, compression='gzip')\n",
    "df_birth['date'] = pd.to_datetime(df_birth.birth_date).dt.date\n",
    "\n",
    "\n",
    "df_birth = pd.merge(df_birth, df_studyID, on='record_id')\n",
    "df_birth['user_id'] = df_birth.evidation_id\n",
    "\n",
    "# There is a missing value in the birthing data. I'm removing it here\n",
    "df_birth = df_birth.drop(index=50)\n",
    "\n",
    "# Bodyport Wave 4\n",
    "key = 'bump/bodyport/wave_4/bodyport.csv.gz'\n",
    "df_bodyport = pandas_from_csv_s3(bucket, key=key, compression='gzip')\n",
    "# OPTIONAL: Convert date format\n",
    "df_bodyport['date'] = pd.to_datetime(df_bodyport.event_date).dt.date \n",
    "\n",
    "# Oura Wave 4\n",
    "key = 'bump/oura/wave_4/oura_sleep.csv.gz'\n",
    "df_sleep = pandas_from_csv_s3(bucket, key=key, compression='gzip')\n",
    "df_sleep['date'] = pd.to_datetime(df_sleep.event_date).dt.date\n",
    "\n",
    "key = 'bump/oura/wave_4/oura_activity.csv.gz'\n",
    "df_activity = pandas_from_csv_s3(bucket, key=key, compression='gzip')\n",
    "df_activity['date'] = pd.to_datetime(df_activity.event_date).dt.date\n",
    "\n",
    "key = 'bump/oura/wave_4/oura_readiness.csv.gz'\n",
    "df_readiness = pandas_from_csv_s3(bucket, key=key, compression='gzip')\n",
    "df_readiness['date'] = pd.to_datetime(df_readiness.event_date).dt.date\n",
    "\n",
    "# Surveys Wave 4\n",
    "key = 'bump/app_activities/wave_4/surveys.csv.gz'\n",
    "df_survey = pandas_from_csv_s3(bucket, key=key, compression='gzip')\n",
    "df_survey['date'] = pd.to_datetime(df_survey.updated_at).dt.date\n",
    "\n",
    "key = 'bump/app_activities/wave_4/quick_activities.csv.gz'\n",
    "df_sam = pandas_from_csv_s3(bucket, key=key, compression='gzip')\n",
    "df_sam['date'] = pd.to_datetime(df_sam.event_date).dt.date\n",
    "\n",
    "dfs = [df_sleep, df_bodyport, df_birth, df_activity, df_readiness, df_survey, df_sam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting fatigue related questions\n",
    "survey_question_str = 'fatigue'\n",
    "\n",
    "df_fatigue = get_survey_question(df_survey, survey_question_str)\n",
    "np.sum(df_fatigue.isna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fatigue[df_fatigue.user_id == 2019]\n",
    "\n",
    "df_fatigue[df_fatigue.date == np.min(df_fatigue.date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_birth[df_birth.user_id==290].birth_date.values[0]\n",
    "b=df_birth[df_birth.user_id==1429].birth_date.values[0]\n",
    "date_range = pd.date_range(a, b, freq='d')\n",
    "date_range\n",
    "date_df = pd.DataFrame()\n",
    "date_df['date'] = date_range.date\n",
    "date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all column names in merged dfs\n",
    "names = []\n",
    "for df in dfs:\n",
    "    [names.append(i) for i in df.columns.to_list()]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyport_features = [\n",
    "    # 'heart_rate',\n",
    "    # 'breath_average',\n",
    "    # 'peripheral_fluid',\n",
    "    # 'total_body_water_percent',\n",
    "    # 'weight_kg'\n",
    "]\n",
    "oura_features = [\n",
    "    # 'hr_lowest',\n",
    "    'hr_average',\n",
    "    'rmssd',\n",
    "    # 'score_deep',\n",
    "    # 'temperature_deviation',\n",
    "    # 'temperature_trend_deviation',\n",
    "    # 'temperature_delta',\n",
    "    # 'duration',\n",
    "    # 'rem',\n",
    "    # 'efficiency',\n",
    "    # 'score_alignment',\n",
    "    # 'score_rem',\n",
    "    # 'light',\n",
    "    # 'onset_latency',\n",
    "    # 'restless',\n",
    "    'breath_average',\n",
    "    # 'score_disturbances',\n",
    "    'score',\n",
    "    # 'score_efficiency',\n",
    "    # 'score_latency',\n",
    "    # 'score_total'\n",
    "]\n",
    "\n",
    "feature_names = bodyport_features + oura_features\n",
    "date_list = [\n",
    "    \"d\", \"id_x\", \n",
    "    \"user_id_x\", \n",
    "    \"identity_id_x\", \n",
    "    \"created_at_x\", \n",
    "    \"updated_at_x\", \n",
    "    \"retrieved_at_x\", \n",
    "    \"subsource_x\", \n",
    "    \"event_date_x\",\n",
    "    \"date\", \"id_y\", \n",
    "    \"user_id_y\", \n",
    "    \"identity_id_y\", \n",
    "    \"created_at_y\", \n",
    "    \"updated_at_y\", \n",
    "    \"retrieved_at_y\", \n",
    "    \"subsource_y\", \n",
    "    \"creation_date\", \n",
    "    \"event_date_y\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import *\n",
    "# merge df_fatigue and df_sleep\n",
    "close_users = []\n",
    "close_users_id = []\n",
    "# start_close_days = 90\n",
    "all_survey_user_id = df_fatigue[['answer_text', 'date', 'user_id']].user_id.unique()\n",
    "#print(len(all_survey_user_id))\n",
    "#print(all_survey_user_id)\n",
    "for user_id in tqdm(all_survey_user_id):\n",
    "    start_time = time.time()\n",
    "    #print(\"Current user id:\", user_id)\n",
    "    if len(df_sleep[df_sleep.user_id==user_id]) == 0:\n",
    "        print(\"No row in df_sleep, continue\")\n",
    "        continue\n",
    "    # selected_user_df = df_fatigue.loc[df_fatigue.user_id == user_id]\n",
    "    # survey_retrived_date = selected_user_df.reset_index()['date'][0]\n",
    "    min_date = np.min(df_fatigue[df_fatigue.user_id == user_id].date)\n",
    "    max_date = np.max(df_fatigue[df_fatigue.user_id == user_id].date)\n",
    "    date_range = pd.date_range(min_date, max_date, freq='d')\n",
    "    selected_fatigue_df = df_fatigue[df_fatigue.user_id == user_id]\n",
    "    selected_fatigue_df = selected_fatigue_df[['answer_text', 'date', 'user_id']]\n",
    "    date_range_df = pd.DataFrame()\n",
    "    \n",
    "    date_range_df['date'] = date_range.date\n",
    "    date_range_df['user_id'] = user_id\n",
    "    #print(date_range_df)\n",
    "    add_date_fatigue_df = pd.merge(date_range_df, selected_fatigue_df, how='left')\n",
    "    #print(selected_fatigue_df)\n",
    "    #print(add_date_fatigue_df)\n",
    "\n",
    "    sleep_features = oura_features + ['date', 'user_id']\n",
    "    merged_df = merge_two_df_by_userid(user_id, add_date_fatigue_df, df_sleep[sleep_features], how='left')\n",
    "    merge_end_time = time.time()\n",
    "    #print('merge_time:', merge_end_time-start_time)\n",
    "    # print(merged_df)\n",
    "    # merged_df = merged_df.fillna(merged_df.mean())\n",
    "    # print(merged_df)\n",
    "    fillna_end_time = time.time()\n",
    "    #print('fillna_time:', fillna_end_time-merge_end_time)\n",
    "    merged_df = merged_df.sort_values(by=['date'], ascending=True)\n",
    "    if len(df_birth[df_birth.user_id == user_id]):\n",
    "        merged_df['birth_date'] = df_birth[df_birth.user_id == user_id].birth_date.values[0]\n",
    "    else:\n",
    "        merged_df['birth_date'] = np.nan\n",
    "    close_users.append(merged_df)\n",
    "    close_users_id.append(user_id)\n",
    "\n",
    "len(close_users_id)\n",
    "    # schedule_birth = birth['birth_scheduled'].to_list()[0] #schedule_birth == 1: induced deliveries; schedule_birth == 2: non induced\n",
    "    # if len(birth) > 0 and pd.isnull(birthdate) == False and schedule_birth == 2:\n",
    "    #     start = birthdate - pd.to_timedelta(start_close_days, unit='d') # pd.to_timedelta(100, unit='d')\n",
    "    #     end = birthdate + pd.to_timedelta(5, unit='d')\n",
    "    #     date_range = pd.date_range(start, end, freq='d')\n",
    "    #     df = get_user(user_id, start, birthdate)\n",
    "    #     dr = pd.DataFrame()\n",
    "    #     dr[\"d\"] = date_range.date\n",
    "    #     dr.set_index(dr.d, inplace=True)\n",
    "    #     df = dr.join(df)\n",
    "    #     df = df[feature_names + date_list]\n",
    "    #     if df.isna().sum().max() < round(start_close_days) / 2: # max null counts in each col is less than 5\n",
    "    #         df.set_index(df.d - df.d.min(), inplace=True)\n",
    "    #         df = df.resample(\"D\").mean()\n",
    "    #         df.set_index(df.index.days, inplace=True)\n",
    "    #         # df = df.interpolate(\"linear\", 0) #linear interpolation on data\n",
    "    #         df = df.fillna(method='ffill')\n",
    "    #         df = df.fillna(df.mean(0))\n",
    "    #         close_users.append(df)\n",
    "    #         close_users_id.append(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_users[0]\n",
    "#df_fatigue[[f for f in ['answer_text', 'date', 'user_id']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(merge_two_df_by_userid(1037, df_fatigue[['answer_text', 'date', 'user_id']], df_sleep[['hr_average', 'date', 'user_id']]).date.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_fatigue[['answer_text', 'date', 'user_id']][df_fatigue.user_id==1037].date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sleep[['hr_average', 'date', 'user_id']][df_sleep.user_id==1037].date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store to local directory for R\n",
    "import os\n",
    "stored_path = os.path.join('.', 'all_date_combined_df_sleep_'+survey_question_str)\n",
    "if not os.path.exists(stored_path):\n",
    "    os.mkdir(stored_path)\n",
    "for df, uid in zip(close_users, close_users_id):\n",
    "    df.to_csv(os.path.join('.', 'all_date_combined_df_sleep_'+survey_question_str, 'user_id_'+str(uid)+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, uid in zip(close_users, close_users_id):\n",
    "    print(uid, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationary test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_user(user_id, start=None, end=None):\n",
    "#     user_sleep = df_sleep[df_sleep.user_id == user_id]#.dropna()\n",
    "#     user_bp = df_bodyport[df_bodyport.user_id == user_id]#.dropna()\n",
    "    \n",
    "#     df2 = pd.merge(user_sleep, user_bp, on=\"date\")\n",
    "\n",
    "#     if \"creation_date\" in df2.columns:\n",
    "#         for i in range(len(df2)):\n",
    "#             df2[\"creation_date\"][i] = dt.datetime.strptime(df2[\"creation_date\"][i], '%Y-%m-%d %H:%M:%S')\n",
    "#     df2.set_index(df2[\"date\"], inplace=True)\n",
    "#     df2.sort_index(inplace=True)\n",
    "    \n",
    "#     if start and end:\n",
    "#         mask = (df2['date'] > np.datetime64(start)) & (df2['date'] <= np.datetime64(end))\n",
    "#         # mask = pd.to_datetime(df2[\"date\"]).between(start.astype(str)[0], end.astype(str)[0], inclusive=True)\n",
    "#         df2 = df2[mask]\n",
    "#     return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #merge all data features\n",
    "# close_users = []\n",
    "# close_users_id = []\n",
    "# start_close_days = 90\n",
    "# for user_id in tqdm(df_birth[['birth_scheduled', 'birth_date', 'user_id']].dropna().user_id.unique()):\n",
    "#     birth = df_birth.loc[df_birth.user_id == user_id]\n",
    "#     birthdate = birth.reset_index()['date'][0]\n",
    "#     schedule_birth = birth['birth_scheduled'].to_list()[0] #schedule_birth == 1: induced deliveries; schedule_birth == 2: non induced\n",
    "#     if len(birth) > 0 and pd.isnull(birthdate) == False and schedule_birth == 2:\n",
    "#         start = birthdate - pd.to_timedelta(start_close_days, unit='d') # pd.to_timedelta(100, unit='d')\n",
    "#         end = birthdate + pd.to_timedelta(5, unit='d')\n",
    "#         date_range = pd.date_range(start, end, freq='d')\n",
    "#         df = get_user(user_id, start, birthdate)\n",
    "#         dr = pd.DataFrame()\n",
    "#         dr[\"d\"] = date_range.date\n",
    "#         dr.set_index(dr.d, inplace=True)\n",
    "#         df = dr.join(df)\n",
    "#         df = df[feature_names + date_list]\n",
    "#         if df.isna().sum().max() < round(start_close_days) / 2: # max null counts in each col is less than 5\n",
    "#             df.set_index(df.d - df.d.min(), inplace=True)\n",
    "#             df = df.resample(\"D\").mean()\n",
    "#             df.set_index(df.index.days, inplace=True)\n",
    "#             # df = df.interpolate(\"linear\", 0) #linear interpolation on data\n",
    "#             df = df.fillna(method='ffill')\n",
    "#             df = df.fillna(df.mean(0))\n",
    "#             close_users.append(df)\n",
    "#             close_users_id.append(user_id)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(close_users_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def exploreDataBirthBA(df, col, user_id):\n",
    "#     plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "#     sns.set_theme(style='darkgrid')\n",
    "#     pdf = df.loc[df.user_id == user_id]    \n",
    "#     plt.figure(figsize=(12,4))\n",
    "#     sns.scatterplot(data=pdf, x='date', y=col, ci=None, color='purple')\n",
    "#     sns.lineplot(data=pdf, x='date', y=col, ci=None)\n",
    "\n",
    "#     # Plot birthing data if it exists for that user\n",
    "#     if (len(df_birth.loc[df_birth.user_id == user_id]) != 0):\n",
    "#         birth = df_birth.loc[df_birth.user_id == user_id].reset_index()\n",
    "#         plt.axvline(x=birth.date, color = 'y', ls='--')\n",
    "#         ymin, ymax = plt.gca().get_ylim()\n",
    "#         xmin, xmax = plt.gca().get_xlim()\n",
    "#         plt.text(birth.date, ymax, birth['date'][0], fontsize=12, color='y')\n",
    "        \n",
    "#         # Dataframe of data before birth\n",
    "#         after = pdf[~(pdf['date'] < birth.date[0])]\n",
    "#         before = pdf[~(pdf['date'] > birth.date[0])]\n",
    "#         before_avg = before[col].mean()\n",
    "#         after_avg = after[col].mean()\n",
    "# #         print('Pre-birth Average: ', before_avg)\n",
    "# #         print('Post-birth Average: ', after_avg)\n",
    "#         plt.hlines(y=before_avg, xmin=xmin, xmax=birth.date, color='blue', linestyles='dashdot')\n",
    "#         plt.hlines(y=after_avg, xmin=birth.date, xmax=xmax, color='red', linestyles='dashdot')\n",
    "# #         sns.lineplot(data=before, x='date', y=col, ci=None, color='r')\n",
    "# #         sns.lineplot(data=after, x='date', y=col, ci=None, color='r')\n",
    "\n",
    "#     plt.xlabel(''); plt.ylabel(col)\n",
    "#     plt.title('User ID: ' + str(user_id))\n",
    "#     plt.show()\n",
    "# exploreDataBirthBA(df_sleep, 'hr_average', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

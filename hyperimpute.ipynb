{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "import pandas as pd\n",
    "import os\n",
    "combined_data_lst = ['combined_oura.csv', 'user_581_survey_data.csv']\n",
    "result_lst = []\n",
    "for f in combined_data_lst:\n",
    "    test_df = pd.read_csv(os.path.join(\".\", \"dataset\", f))\n",
    "\n",
    "    # test_df.to_csv('./dataset/'+f)\n",
    "    print(f)\n",
    "    #test_df['d']\n",
    "    imputer = Imputers().get(\"hyperimpute\")\n",
    "    # test_df.drop('d', inplace=True, axis=1)\n",
    "    result_lst.append(compare_models(\n",
    "        name=\"example\",\n",
    "        evaluated_model=imputer,\n",
    "        X_raw=test_df,\n",
    "        ref_methods=[\"ice\", \"missforest\", \"mice\"],\n",
    "        scenarios=[\"MAR\"],\n",
    "        miss_pct=[0.1, 0.3, 0.5, 0.7],\n",
    "        n_iter=3,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "oura_df_list = []\n",
    "for f in os.listdir('./dataset'):\n",
    "    if 'oura' in f:\n",
    "        subset_df = pd.read_csv(os.path.join('.', 'dataset', f))\n",
    "        \n",
    "        oura_df_list.append(subset_df)\n",
    "combined_oura_df = pd.concat(oura_df_list, ignore_index=True)\n",
    "combined_oura_df = combined_oura_df.loc[:, ~combined_oura_df.columns.str.contains('^Unnamed')]\n",
    "combined_oura_df.to_csv(os.path.join('.', 'dataset', 'combined_oura.csv'), index=False)\n",
    "combined_oura_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for f in os.listdir('/domino/datasets/local/Bump/'):\n",
    "    test_df = pd.read_csv('/domino/datasets/local/Bump/'+f)\n",
    "\n",
    "    \n",
    "    #test_df['d']\n",
    "    test_df.drop('d', inplace=True, axis=1)\n",
    "    test_df.to_csv('./dataset/'+f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lst[0]\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# for col in rmse_oura.columns.to_list():\n",
    "#     if col != 'Scenario' and 'miss_pct' not in col:\n",
    "#         new_col = col\n",
    "#         if \":\" in col:\n",
    "#             new_col = col.split(\":\")[1]\n",
    "#         rmse_oura[new_col + '_sd'] = rmse_oura[col].apply(lambda x: x[1])\n",
    "#         rmse_oura[new_col + '_mean'] = rmse_oura[col].apply(lambda x: x[0])\n",
    "def reshape_hyperimpute_output(rmse_oura):\n",
    "    rmse_oura = rmse_oura.rename(columns = {'Evaluated: hyperimpute':'hyperimpute'})\n",
    "    rmse_oura=rmse_oura.melt(id_vars=['Scenario', 'miss_pct [0, 1]'], var_name=\"Model\", value_name=\"value\")\n",
    "    rmse_oura['mean'] = rmse_oura['value'].apply(lambda x: x[0])\n",
    "    rmse_oura['sd'] = rmse_oura['value'].apply(lambda x: x[1])\n",
    "    return rmse_oura\n",
    "#rmse_oura.pivot_table()\n",
    "def plot_missingness_performance(rmse_oura, title):\n",
    "    fig,ax = plt.subplots(figsize=(14,8))\n",
    "    sns.set(style= \"whitegrid\")\n",
    "    lvls = rmse_oura.Model.unique()\n",
    "    for i in lvls:\n",
    "        ax.errorbar(x = rmse_oura[rmse_oura['Model']==i][\"miss_pct [0, 1]\"],\n",
    "                    y=rmse_oura[rmse_oura['Model']==i][\"mean\"], \n",
    "                    yerr=rmse_oura[rmse_oura['Model']==i][\"sd\"],label=i)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    fig.show()\n",
    "rmse_oura = pd.DataFrame(result_lst[0]['rmse'], columns=result_lst[0]['headers'])\n",
    "rmse_oura = reshape_hyperimpute_output(rmse_oura)\n",
    "plot_missingness_performance(rmse_oura, \"RMSE for oura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_survey = pd.DataFrame(result_lst[1]['rmse'], columns=result_lst[1]['headers'])\n",
    "rmse_survey = reshape_hyperimpute_output(rmse_survey)\n",
    "plot_missingness_performance(rmse_survey, \"RMSE for survey data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "oura_df_list = []\n",
    "for f in os.listdir('./dataset'):\n",
    "    if 'oura' in f:\n",
    "        subset_df = pd.read_csv(os.path.join('.', 'dataset', f))\n",
    "        \n",
    "        oura_df_list.append(subset_df)\n",
    "combined_oura_df = pd.concat(oura_df_list, ignore_index=True)\n",
    "combined_oura_df = combined_oura_df.loc[:, ~combined_oura_df.columns.str.contains('^Unnamed')]\n",
    "combined_oura_df.to_csv(os.path.join('.', 'dataset', 'combined_oura.csv'), index=False)\n",
    "combined_oura_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./dataset/user_581_survey_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "imputers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

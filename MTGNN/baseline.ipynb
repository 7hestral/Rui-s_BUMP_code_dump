{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "import torch\n",
    "from net import gtnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_users_above_criteria = [\n",
    "        1032,\n",
    "        581,\n",
    "        407,\n",
    "        290,\n",
    "        1436,\n",
    "        1000,\n",
    "        95,\n",
    "        1386,\n",
    "        1431,\n",
    "        992,\n",
    "        1717,\n",
    "        1441,\n",
    "        122,\n",
    "        977,\n",
    "        293,\n",
    "        1700,\n",
    "        1744,\n",
    "        622,\n",
    "\n",
    "        192,\n",
    "        1373,\n",
    "        84,\n",
    "        1393,\n",
    "        1432,\n",
    "        1378,\n",
    "        225,\n",
    "        1753,\n",
    "        2084,\n",
    "        969,\n",
    "        280,\n",
    "        99,\n",
    "        53,\n",
    "        983,\n",
    "        2068,\n",
    "        193,\n",
    "        2056,\n",
    "        2016,\n",
    "        2109, \n",
    "        1995,\n",
    "        1706,\n",
    "        2015,\n",
    "        186,\n",
    "        137,\n",
    "        1658,\n",
    "        2083,\n",
    "        1383,\n",
    "        429,\n",
    "        279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 14\n",
    "selected_user = 1032\n",
    "# 1431 and 95 have bug, excluded for now\n",
    "user_lst = list_users_above_criteria\n",
    "def match_dataset_date(selected_user, seq_len, classify_user=False):\n",
    "    y_df = pd.read_csv(f'/mnt/results/user_{selected_user}_puqe.csv')\n",
    "    x_df = pd.read_csv(f'/mnt/results/user_{selected_user}_activity_bodyport_hyperimpute_with_date.csv')\n",
    "    y_df['date'] = pd.to_datetime(y_df['date'])\n",
    "    x_df['date'] = pd.to_datetime(x_df['date'])\n",
    "    dataset = []\n",
    "    for i in range(len(y_df)):\n",
    "        row = y_df.iloc[i]\n",
    "        day_before = row['date'] - datetime.timedelta(days=seq_len)\n",
    "        x = (x_df[(x_df['date'] > day_before) & (x_df['date'] <= row['date'])])\n",
    "        if classify_user:\n",
    "            dataset.append((x.drop('date', axis=1).to_numpy(), selected_user))\n",
    "        else:\n",
    "            dataset.append((x.drop('date', axis=1).to_numpy(), row['answer_text']))\n",
    "    return dataset\n",
    "# gnn_dataset_1032 = match_dataset_date(selected_user, seq_len)\n",
    "# gnn_dataset_1032 = list(filter(lambda x: len(x[0])>=seq_len, gnn_dataset))\n",
    "# baseline_dataset_1032 = list(map(lambda x: (x[0][-7:], x[1]), gnn_dataset))\n",
    "baseline_ds_lst = []\n",
    "gnn_ds_lst = []\n",
    "for u in user_lst:\n",
    "    temp_dataset = match_dataset_date(u, seq_len, classify_user=True)\n",
    "    temp_dataset = list(filter(lambda x: len(x[0])>=seq_len, temp_dataset))\n",
    "    gnn_ds_lst.append(temp_dataset)\n",
    "    baseline_dataset = list(map(lambda x: (x[0][-7:], x[1]), temp_dataset))\n",
    "    baseline_ds_lst.append(baseline_dataset)\n",
    "print(len(baseline_ds_lst))\n",
    "print(len(gnn_ds_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dynamic time warping\n",
    "# from tslearn.metrics import dtw\n",
    "# def get_similarities(target_user, user_lst):\n",
    "#     result = []\n",
    "#     target_user_df = pd.read_csv(f'/mnt/results/user_{target_user}_activity_bodyport_hyperimpute_with_date.csv').drop('date', axis=1)\n",
    "#     for user in user_lst:\n",
    "#         if user == target_user:\n",
    "#             continue\n",
    "#         else:\n",
    "#             curr_user_df = pd.read_csv(f'/mnt/results/user_{user}_activity_bodyport_hyperimpute_with_date.csv').drop('date', axis=1)\n",
    "#             result.append((user, dtw(target_user_df, curr_user_df)))\n",
    "#     return sorted(result, key=lambda x: x[1], reverse=True)\n",
    "# print(get_similarities(290, user_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'data': '/mnt/results/user_456546_activity_bodyport_hyperimpute.csv', 'log_interval': 2000, 'optim': 'adam', 'L1Loss': True, 'normalize': 2, 'device': 'cuda:0', 'gcn_true': True, 'buildA_true': True, 'gcn_depth': 2, 'num_nodes': 19, 'dropout': 0.3, 'subgraph_size': 19, 'node_dim': 40, 'dilation_exponential': 2, 'conv_channels': 16, 'residual_channels': 16, 'skip_channels': 32, 'end_channels': 64, 'in_dim': 1, 'seq_in_len': 14, 'seq_out_len': 1, 'horizon': 7, 'layers': 5, 'batch_size': 32, 'lr': 0.0001, 'weight_decay': 1e-05, 'clip': 5, 'propalpha': 0.05, 'tanhalpha': 3, 'epochs': 50, 'num_split': 1, 'step_size': 100}\n",
    "device = torch.device(args['device'])\n",
    "torch.set_num_threads(3)\n",
    "for i in range(len(user_lst)):\n",
    "    # model = gtnet(args['gcn_true'], args['buildA_true'], args['gcn_depth'], args['num_nodes'],\n",
    "    #         device, dropout=args['dropout'], subgraph_size=args['subgraph_size'],\n",
    "    #         node_dim=args['node_dim'], dilation_exponential=args['dilation_exponential'],\n",
    "    #         conv_channels=args['conv_channels'], residual_channels=args['residual_channels'],\n",
    "    #         skip_channels=args['skip_channels'], end_channels= args['end_channels'],\n",
    "    #         seq_length=args['seq_in_len'], in_dim=args['in_dim'], out_dim=args['seq_out_len'],\n",
    "    #         layers=args['layers'], propalpha=args['propalpha'], tanhalpha=args['tanhalpha'], layer_norm_affline=False)\n",
    "    model = torch.load(f'/mnt/results/model/model_{user_lst[i]}.pt')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for j in range(len(gnn_ds_lst[i])):\n",
    "        # print(d[0].shape)\n",
    "        curr = gnn_ds_lst[i][j]\n",
    "        X = torch.from_numpy(curr[0]).unsqueeze(0).unsqueeze(0).permute(0,1,3,2)\n",
    "        # print(X.shape)\n",
    "        X.to(device)\n",
    "        X = X.type(torch.cuda.FloatTensor)\n",
    "        out = model(X)\n",
    "        out = out.squeeze(0).squeeze(0).squeeze(-1)\n",
    "        gnn_ds_lst[i][j] = out.detach().cpu().numpy(), gnn_ds_lst[i][j][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_ds = []\n",
    "for ds in gnn_ds_lst:\n",
    "    gnn_ds.extend(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_ds = []\n",
    "\n",
    "for ds in baseline_ds_lst:\n",
    "    baseline_ds.extend(ds)\n",
    "len(baseline_ds)\n",
    "random.seed(90)\n",
    "both_lst = list(zip(baseline_ds, gnn_ds))\n",
    "random.shuffle(both_lst)\n",
    "baseline_ds, gnn_ds = zip(*both_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_x = list(map(lambda x: x[0].ravel(), baseline_ds))\n",
    "\n",
    "\n",
    "baseline_y = list(map(lambda x: x[1], baseline_ds))\n",
    "\n",
    "\n",
    "cut_pt = int(len(baseline_ds) * 0.8)\n",
    "\n",
    "baseline_x_train = baseline_x[:cut_pt]\n",
    "baseline_x_test = baseline_x[cut_pt:]\n",
    "baseline_y_train = baseline_y[:cut_pt]\n",
    "baseline_y_test = baseline_y[cut_pt:]\n",
    "\n",
    "print(len(gnn_ds))\n",
    "print(len(baseline_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_result(x, true, clf, predict_user=False):\n",
    "    pred = clf.predict(x)\n",
    "    recall = recall_score(y_true=true, y_pred=pred, average='micro')\n",
    "    #roc_auc = roc_auc_score(y_true=gnn_y_test, y_score=gnn_y_pred, average='micro', multi_class='ovr')\n",
    "    precision = precision_score(y_true=true, y_pred=pred, average='micro')\n",
    "    print(f\"Recall: {recall}\")\n",
    "    #print(f\"ROC AUC: {roc_auc}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    cm = confusion_matrix(y_true=true, y_pred=pred)\n",
    "    classes = ['mild','medium','severe']\n",
    "    if predict_user:\n",
    "        classes = list(map(lambda x: str(x), user_lst))\n",
    "        classes = None\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                        index = classes, \n",
    "                        columns = classes)\n",
    "\n",
    "    #Plotting the confusion matrix\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actal Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=90, max_iter=300, hidden_layer_sizes=(50, 15,)).fit(baseline_x_train, baseline_y_train)\n",
    "clf.score(baseline_x_test, baseline_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result(baseline_x_test, baseline_y_test, clf, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_x = list(map(lambda x: x[0], gnn_ds))\n",
    "gnn_y = list(map(lambda x: x[1], gnn_ds))\n",
    "gnn_x_train = gnn_x[:cut_pt]\n",
    "gnn_x_test = gnn_x[cut_pt:]\n",
    "gnn_y_train = gnn_y[:cut_pt]\n",
    "gnn_y_test = gnn_y[cut_pt:]\n",
    "clf = MLPClassifier(random_state=90, max_iter=300, hidden_layer_sizes=(40,8,)).fit(gnn_x_train, gnn_y_train)\n",
    "clf.score(gnn_x_test, gnn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "analysis_result(gnn_x_test, gnn_y_test, clf, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

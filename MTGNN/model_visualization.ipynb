{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "import torch\n",
    "from net import gtnet\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'/mnt/results/model/model_all_pop_edema_0_GNN.pt')\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = model.gc(model.idx).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gc(model.idx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Active calories','Calories','Daily movement','Minutes of high-intensity activity','Minutes of inactive','Minutes of low-intensity activity','Minutes of medium-intensity activity','High-intensity MET','Inactive MET','Low-intensity MET','Medium-intensity MET','Minutes of non-wear','Minutes of rest','Total daily steps','Impedance magnitude','Impedance phase','Weight','Respiratory rate','Edema']\n",
    "def analysis_result(mat, features):\n",
    "    cm_df = pd.DataFrame(mat,   \n",
    "                    index = features, \n",
    "                    columns = features)\n",
    "\n",
    "    #Plotting the confusion matrix\n",
    "    plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.savefig('/mnt/results/plots/adj.svg')\n",
    "    plt.show()\n",
    "analysis_result(adj, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from net import gtnet\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "from util import *\n",
    "from trainer import Optim\n",
    "from sequence_dataset import SequenceDataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import DataLoader \n",
    "from lstm import LSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "list_users_above_criteria = [53, 55, 137, 159, 410, 581, 622, 987, 1426]\n",
    "train_df_lst = []\n",
    "val_df_lst = []\n",
    "train_dataset_lst = []\n",
    "val_dataset_lst = []\n",
    "device = torch.device(\"cuda:0\")\n",
    "task_name = 'edema_pred'\n",
    "\n",
    "train_user_label = []\n",
    "val_user_label = []\n",
    "\n",
    "for u in list_users_above_criteria:\n",
    "    file_name = f'/mnt/results/{task_name}/user_{u}_{task_name}_hyperimpute.csv'\n",
    "    curr_all_data = np.loadtxt(file_name, delimiter=',')\n",
    "    num_all_data, _ = curr_all_data.shape\n",
    "    curr_train_data = curr_all_data[:int(round(num_all_data * 0.8)), :]\n",
    "    curr_val_data = curr_all_data[int(round(num_all_data * 0.8)):, :]\n",
    "    train_df_lst.append(curr_train_data)\n",
    "    val_df_lst.append(curr_val_data)\n",
    "\n",
    "# normalization\n",
    "normalized_train_df_lst, min_value_lst, max_value_lst = min_max_normalization(train_df_lst)\n",
    "normalized_val_df_lst, _, _ = min_max_normalization(val_df_lst, min_value_lst=min_value_lst, max_value_lst=max_value_lst)\n",
    "\n",
    "# create sequential datasets\n",
    "for i, curr_train_data in enumerate(normalized_train_df_lst):\n",
    "    curr_train_dataset = SequenceDataset(curr_train_data, 1, 7, device)\n",
    "    train_dataset_lst.append(curr_train_dataset)\n",
    "    train_user_label.extend([list_users_above_criteria[i]] * len(curr_train_dataset))\n",
    "    \n",
    "for i, curr_val_data in enumerate(normalized_val_df_lst):\n",
    "    curr_val_dataset = SequenceDataset(curr_val_data, 1, 7, device)\n",
    "    val_dataset_lst.append(curr_val_dataset)\n",
    "    val_user_label.extend([list_users_above_criteria[i]] * len(curr_val_dataset))\n",
    "\n",
    "\n",
    "all_user_label = train_user_label + val_user_label\n",
    "\n",
    "# aggregate them\n",
    "aggregated_train_dataset = ConcatDataset(train_dataset_lst)\n",
    "aggregated_val_dataset = ConcatDataset(val_dataset_lst)\n",
    "all_dataset = ConcatDataset([aggregated_train_dataset, aggregated_val_dataset])\n",
    "train_dataloader = DataLoader(aggregated_train_dataset, batch_size=32, shuffle=False)\n",
    "val_dataloader = DataLoader(aggregated_val_dataset, batch_size=32, shuffle=False)\n",
    "dataloader = DataLoader(all_dataset, batch_size=32, shuffle=False)\n",
    "num_train_data = len(aggregated_train_dataset)\n",
    "num_val_data = len(aggregated_val_dataset)\n",
    "num_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, Callable\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model, layers):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.layers = layers\n",
    "        self._features = {layer: torch.empty(0) for layer in layers}\n",
    "\n",
    "        for layer_id in layers:\n",
    "            layer = dict([*self.model.named_modules()])[layer_id]\n",
    "            layer.register_forward_hook(self.save_outputs_hook(layer_id))\n",
    "\n",
    "    def save_outputs_hook(self, layer_id):\n",
    "        def fn(_, __, output):\n",
    "            self._features[layer_id] = output\n",
    "        return fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.model(x)\n",
    "        return self._features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = {'data': '/mnt/results/user_1431_activity_bodyport_hyperimpute.csv', 'log_interval': 2000, 'save': '/mnt/results/model/model_all_pop_edema_0_GNN.pt', 'optim': 'adam', 'L1Loss': True, 'normalize': 0, 'device': 'cuda:0', 'gcn_true': True, 'buildA_true': True, 'gcn_depth': 2, 'num_nodes': 21, 'dropout': 0.3, 'subgraph_size': 21, 'node_dim': 40, 'dilation_exponential': 2, 'conv_channels': 16, 'residual_channels': 16, 'skip_channels': 32, 'end_channels': 64, 'in_dim': 1, 'seq_in_len': 7, 'seq_out_len': 1, 'horizon': 1, 'layers': 5, 'batch_size': 32, 'lr': 0.0001, 'weight_decay': 1e-05, 'clip': 5, 'propalpha': 0.05, 'tanhalpha': 3, 'epochs': 50, 'num_split': 1, 'step_size': 100}\n",
    "# model = gtnet(args['gcn_true'], args['buildA_true'], args['gcn_depth'], args['num_nodes'],\n",
    "#                     device, dropout=args['dropout'], subgraph_size=args['subgraph_size'],\n",
    "#                     node_dim=args['node_dim'], dilation_exponential=args['dilation_exponential'],\n",
    "#                     conv_channels=args['conv_channels'], residual_channels=args['residual_channels'],\n",
    "#                     skip_channels=args['skip_channels'], end_channels= args['end_channels'],\n",
    "#                     seq_length=args['seq_in_len'], in_dim=args['in_dim'], out_dim=args['seq_out_len'],\n",
    "#                     layers=args['layers'], propalpha=args['propalpha'], tanhalpha=args['tanhalpha'], layer_norm_affline=False)\n",
    "# torch.load(f'/mnt/results/model/model_all_pop_edema_0_GNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtnet_features = FeatureExtractor(model, layers=[\"end_conv_1\"])\n",
    "output_lst = []\n",
    "edema_lst = []\n",
    "for X, Y in dataloader:\n",
    "    X = X.to(device)\n",
    "    Y = Y.to(device)\n",
    "    feature_size = X.shape[-1]\n",
    "\n",
    "    X = torch.unsqueeze(X,dim=1)\n",
    "    X = X.transpose(2,3)\n",
    "    edema_label = Y[:, -1].unsqueeze(-1).cpu().detach().numpy()\n",
    "    edema_lst.append(edema_label)\n",
    "    print(edema_label.shape)\n",
    "    with torch.no_grad():\n",
    "        output = gtnet_features(X)['end_conv_1']\n",
    "\n",
    "        output_lst.append(output.squeeze(-1).view(output.shape[0], -1).cpu().detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edema_lst = np.concatenate(edema_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.concatenate(output_lst, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300, random_state=42)\n",
    "    # tsne_results = tsne.fit_transform(pca_result)\n",
    "tsne_results = tsne.fit_transform(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne = pd.DataFrame(tsne_results, columns=[\"X\", \"Y\"])\n",
    "\n",
    "df_tsne[\"User_labels\"] = all_user_label\n",
    "df_tsne[\"User_labels\"] = df_tsne[\"User_labels\"].apply(lambda i: str(i))\n",
    "\n",
    "df_tsne[\"Training_set\"] = [True] * num_train_data + [False] * num_val_data\n",
    "markers_dict = {\n",
    "    True: 'o',\n",
    "    False: 'X',\n",
    "}\n",
    "df_tsne[\"Edema_label\"] = edema_lst\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 15))\n",
    "# plt.figure(figsize=(16,16))\n",
    "sns.scatterplot(\n",
    "    x=\"X\", y=\"Y\",\n",
    "    hue=\"User_labels\",\n",
    "    style=\"Training_set\",\n",
    "    data=df_tsne,\n",
    "    legend=\"full\", s=70,\n",
    "    alpha=0.9,\n",
    "    markers=markers_dict,\n",
    "    ax=axs[0]\n",
    ")\n",
    "# plt.savefig('/mnt/results/plots/embedding_no_labels.svg')\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"X\", y=\"Y\",\n",
    "    hue=\"Edema_label\",\n",
    "    style=\"Training_set\",\n",
    "    data=df_tsne,\n",
    "    legend=\"full\", s=70,\n",
    "    alpha=0.9,\n",
    "    markers=markers_dict,\n",
    "    ax=axs[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.savefig('/mnt/results/plots/embedding_with_labels.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

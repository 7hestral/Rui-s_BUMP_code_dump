{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-vyjw2rt8 because the default path (/home/ubuntu/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
    }
   ],
   "source": [
    "import os\n",
    "from src.utils import data_load\n",
    "import pandas as pd\n",
    "from src.s3_utils import pandas_from_csv_s3\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_survey_question, na_rate\n",
    "import torch\n",
    "import matplotlib.dates as mdates\n",
    "import pingouin as pg\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survey = data_load(data_keys={\"surveys\"}, wave=7)['surveys']\n",
    "# df_birth = data_load(data_keys={\"birth\"}, wave=5)['birth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_148_level = {\"Yes\": 0, \"No\": 0}\n",
    "question_149_to_157_level = {\"Never\": 1, 'Sometimes': 2, 'Regularly': 3, 'Often': 4, 'Always': 5}\n",
    "question_158_level = {\"Never\": 5, 'Sometimes': 4, 'Regularly': 3, 'Often': 2, 'Always': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_id_lst = list(range(148, 159))\n",
    "num_questions = len(list(range(148, 159)))\n",
    "question_levels_lst = [question_149_to_157_level] * num_questions\n",
    "question_levels_lst[0] = question_148_level\n",
    "question_levels_lst[-1] = question_158_level\n",
    "question_level_mapping_dict = dict(zip(question_id_lst, question_levels_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fas = df_survey.loc[df_survey['title'] =='Fatigue survey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_answer_to_int(row):\n",
    "    curr_level_mapping = question_level_mapping_dict[row['question_id']]\n",
    "    return curr_level_mapping[row['answer_text']]\n",
    "df_fas['fas_score'] = df_fas.apply(map_answer_to_int, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_fas = df_fas.groupby(['user_id', 'date'])['fas_score'].sum().reset_index()\n",
    "grouped_df_fas['date'] = pd.to_datetime(grouped_df_fas['date'])\n",
    "grouped_df_fas['week_year'] = grouped_df_fas['date'].dt.strftime('%Y-%U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      user_id       date  fas_score week_year\n0          28 2021-02-24         28   2021-08\n1          28 2021-03-02         34   2021-09\n2          28 2021-03-09         28   2021-10\n3          28 2021-03-16         31   2021-11\n4          28 2021-03-23         26   2021-12\n...       ...        ...        ...       ...\n8752     2664 2023-01-30         17   2023-05\n8753     2664 2023-02-06         17   2023-06\n8754     2664 2023-02-13         17   2023-07\n8755     2664 2023-02-20         17   2023-08\n8756     2664 2023-02-27         16   2023-09\n\n[8757 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>date</th>\n      <th>fas_score</th>\n      <th>week_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28</td>\n      <td>2021-02-24</td>\n      <td>28</td>\n      <td>2021-08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28</td>\n      <td>2021-03-02</td>\n      <td>34</td>\n      <td>2021-09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>2021-03-09</td>\n      <td>28</td>\n      <td>2021-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>2021-03-16</td>\n      <td>31</td>\n      <td>2021-11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>2021-03-23</td>\n      <td>26</td>\n      <td>2021-12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8752</th>\n      <td>2664</td>\n      <td>2023-01-30</td>\n      <td>17</td>\n      <td>2023-05</td>\n    </tr>\n    <tr>\n      <th>8753</th>\n      <td>2664</td>\n      <td>2023-02-06</td>\n      <td>17</td>\n      <td>2023-06</td>\n    </tr>\n    <tr>\n      <th>8754</th>\n      <td>2664</td>\n      <td>2023-02-13</td>\n      <td>17</td>\n      <td>2023-07</td>\n    </tr>\n    <tr>\n      <th>8755</th>\n      <td>2664</td>\n      <td>2023-02-20</td>\n      <td>17</td>\n      <td>2023-08</td>\n    </tr>\n    <tr>\n      <th>8756</th>\n      <td>2664</td>\n      <td>2023-02-27</td>\n      <td>16</td>\n      <td>2023-09</td>\n    </tr>\n  </tbody>\n</table>\n<p>8757 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "grouped_df_fas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    user_id       date  fas_score week_year\n25       28 2021-09-21         36   2021-38",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>date</th>\n      <th>fas_score</th>\n      <th>week_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>28</td>\n      <td>2021-09-21</td>\n      <td>36</td>\n      <td>2021-38</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "curr_user_fas[curr_user_fas['date'] == '2021-09-21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dates_within_one_week(date):\n",
    "    week_dates = [(pd.to_datetime(date) - timedelta(days=i)) for i in range(7)]\n",
    "    return week_dates\n",
    "\n",
    "class SameDayMappingDataset(Dataset):\n",
    "    def __init__(self, dataset_x, dataset_y, user_id, feature_name_lst_x, feature_name_lst_y, train_time_steps, target_time_steps, one_week_back=True, normalize=True):\n",
    "        self.user_id = user_id\n",
    "        self.feature_name_lst_x = feature_name_lst_x\n",
    "        self.feature_name_lst_y = feature_name_lst_y\n",
    "        self.one_week_back = one_week_back\n",
    "        self.train_time_steps = train_time_steps\n",
    "        self.target_time_steps = target_time_steps\n",
    "        if normalize:\n",
    "            self.dataset_x = self._normalize(dataset_x, feature_name_lst_x, x_true=True)\n",
    "            self.dataset_y = self._normalize(dataset_y, feature_name_lst_y, x_true=False)\n",
    "        else:\n",
    "            self.dataset_x = dataset_x\n",
    "            self.dataset_y = dataset_y\n",
    "        # 0 impute\n",
    "\n",
    "        mean_value = 0\n",
    "        self.dataset_x = self.dataset_x.fillna(value=mean_value)\n",
    "\n",
    "    def _normalize(self, df, feature_names, x_true):\n",
    "        if self.one_week_back:\n",
    "\n",
    "            if x_true:\n",
    "                dates_with_one_week = []\n",
    "                for date in self.train_time_steps:\n",
    "                    week_dates = get_dates_within_one_week(date)\n",
    "                    dates_with_one_week.extend(week_dates)\n",
    "                train_dates = [date.strftime('%Y-%m-%d') for date in dates_with_one_week]\n",
    "            else:\n",
    "                train_dates = self.train_time_steps\n",
    "\n",
    "            train_indices = df.index[df['date'].isin(train_dates)]\n",
    "            assert len(train_indices) != 0\n",
    "            def min_max_normalize_subset(feature):\n",
    "                if isinstance(feature.iloc[0], str):\n",
    "                    return feature \n",
    "                min_val = feature.iloc[train_indices].min()\n",
    "                max_val = feature.iloc[train_indices].max()\n",
    "                if min_val == max_val:\n",
    "                    max_val += 1\n",
    "                return (feature - min_val) / (max_val - min_val)\n",
    "            df[feature_names] = df[feature_names].apply(min_max_normalize_subset)\n",
    "            return df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target_time_steps)\n",
    "    def __getitem__(self, idx):\n",
    "        time_step = self.target_time_steps[idx]\n",
    "        print(time_step)\n",
    "        # print(self.dataset_y)\n",
    "        y = self.dataset_y[self.dataset_y['date'] == time_step][self.feature_name_lst_y].values\n",
    "\n",
    "        print(y.shape)\n",
    "        if self.one_week_back:\n",
    "            prev_week_dates = get_dates_within_one_week(time_step)\n",
    "            x = self.dataset_x[self.dataset_x['date'].isin(prev_week_dates)][self.feature_name_lst_x].values\n",
    "        else:\n",
    "            x = self.dataset_x[self.dataset_x['date'].isin(time_step)][self.feature_name_lst_x].values\n",
    "        print(x.shape)\n",
    "        return {\"X\": x, \"Y\": y, \"user_id\": self.user_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2021-11-23\n(1, 1)\n(7, 1)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'X': array([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]]),\n 'Y': array([[0.52631579]]),\n 'user_id': 28}"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for curr_user in grouped_df_fas['user_id'].unique():\n",
    "    # curr_user = 28\n",
    "    curr_user_fas = grouped_df_fas[grouped_df_fas['user_id'] == curr_user]\n",
    "    fas_time = list(curr_user_fas['date'].unique())\n",
    "    daily_csv_path = f'/mnt/dataset/fatigue/user_{curr_user}_fatigue_label.csv'\n",
    "    if not os.path.exists(daily_csv_path):\n",
    "        #print(\"Empty Edema\")\n",
    "        continue\n",
    "    curr_user_daily_df = pd.read_csv(daily_csv_path).groupby(\"date\", as_index = False).first()[['date', 'fatigue']]\n",
    "    curr_user_daily_df['date'] = pd.to_datetime(curr_user_daily_df['date'])\n",
    "    daily_time = list(curr_user_daily_df['date'].unique())\n",
    "    available_time = list(set(daily_time).intersection(fas_time))\n",
    "    available_time = pd.to_datetime(available_time)\n",
    "    available_time = [date.strftime('%Y-%m-%d') for date in available_time]\n",
    "    train_times = available_time[:int(len(available_time) * 0.8)]\n",
    "    test_times = available_time[int(len(available_time) * 0.8):]\n",
    "\n",
    "    train_set = SameDayMappingDataset(dataset_y = curr_user_fas, dataset_x = curr_user_daily_df, \n",
    "    user_id=28, feature_name_lst_y=['fas_score'], feature_name_lst_x=['fatigue'], train_time_steps=train_times, target_time_steps=train_times)\n",
    "    test_set = SameDayMappingDataset(dataset_y = curr_user_fas, dataset_x = curr_user_daily_df, \n",
    "    user_id=28, feature_name_lst_y=['fas_score'], feature_name_lst_x=['fatigue'], train_time_steps=train_times, target_time_steps=test_times)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitmyvenvvenvd1e5e9afda854db5b7246ed89d30986e",
   "display_name": "Python 3.7.0 64-bit ('myvenv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}